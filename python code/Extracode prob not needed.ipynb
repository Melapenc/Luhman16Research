{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_com_x = diff_arr(centroid_com_arr_x1)\n",
    "cen_com_y = diff_arr(centroid_com_arr_y1)\n",
    "cen_2dG_x = diff_arr(centroid_2dG_arr_x2)\n",
    "cen_2dG_y = diff_arr(centroid_2dG_arr_y2)\n",
    "\n",
    "box_size_arr = np.linspace(3,31,15)\n",
    "# difference plot\n",
    "# plt.plot(box_size,cen_com_x,'.')\n",
    "# plt.plot(box_size,cen_com_y,'.')\n",
    "# plt.plot(box_size,cen_2dG_x,'.')\n",
    "# plt.plot(box_size,cen_2dG_y,'.')\n",
    "\n",
    "# will determine what box size we should use\n",
    "print('at time slice: ',time_i)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax1.plot(box_size_arr,cen_com_x,'.',label = 'COM: x')\n",
    "ax1.plot(box_size_arr,cen_com_y,'.',label = 'COM: y')\n",
    "ax2.plot(box_size_arr,cen_2dG_x,'.',label = '2dG: x')\n",
    "ax2.plot(box_size_arr,cen_2dG_y,'.',label = '2dG: y')\n",
    "ax1.set_title('COM')\n",
    "ax2.set_title('2dG')\n",
    "plt.show\n",
    "# best used at box size 9 or 10# from photutils import CircularAperture\n",
    "# from photutils import aperture_photometry\n",
    "\n",
    "# # print(box_size_arr,'\\n')\n",
    "# # print(centroid_2dG_arr_x2,'\\n')\n",
    "# # print(centroid_2dG_arr_y2,'\\n')\n",
    "\n",
    "# # index_nine = 3 #box size 9\n",
    "\n",
    "# # index_fifteen = 6  #box size 15\n",
    "# # radius = int(box_size_arr[index_nine])\n",
    "# radius = 13\n",
    "# val_2dg_x = centroid_2dG_arr_x2[14]\n",
    "# val_2dg_y = centroid_2dG_arr_y2[14]\n",
    "\n",
    "# print(radius,val_2dg_x,val_2dg_y)\n",
    "\n",
    "\n",
    "# # for positions we will take the 2dg Gaussian outputs.\n",
    "\n",
    "# positions = [(val_2dg_x, val_2dg_y)]\n",
    "# apertures = CircularAperture(positions, r=radius)\n",
    "# print(apertures)\n",
    "\n",
    "# phot_table = aperture_photometry(counts_image[0,:,:],apertures)\n",
    "# print(phot_table)\n",
    "\n",
    "# # another aperture radius \n",
    "\n",
    "# ---\\\n",
    "# radius = 20\n",
    "# val_2dg_x = centroid_2dG_arr_x2[14]\n",
    "# # val_2dg_y = centroid_2dG_arr_y2[14]\n",
    "\n",
    "# # print(radius,val_2dg_x,val_2dg_y)\n",
    "\n",
    "\n",
    "# # # for positions we will take the 2dg Gaussian outputs.\n",
    "\n",
    "# # positions = [(val_2dg_x, val_2dg_y)]\n",
    "# # apertures = CircularAperture(positions, r=radius)\n",
    "# # print(apertures)\n",
    "\n",
    "# # phot_table = aperture_photometry(counts_image[0,:,:],apertures)\n",
    "# # print(phot_table)\n",
    "# --\n",
    "\n",
    "# apert_sum_r3 = 385848.1178699848\n",
    "# apert_sum_r2 = 311819.7046191514\n",
    "# num = -apert_sum_r3 + apert_sum_r2\n",
    "# # print(num)\n",
    "\n",
    "# radius =np.linspace(1,15,15)\n",
    "# # radius\n",
    "\n",
    "# # find the photometry within the aperture. we are taking \n",
    "# # backrground pixel of the flux and will be trying to add \n",
    "# # it back in (?)\n",
    "from photutils import CircularAperture\n",
    "from photutils import aperture_photometry\n",
    "\n",
    "# # print(box_size_arr,'\\n')\n",
    "# # print(centroid_2dG_arr_x2,'\\n')\n",
    "# # print(centroid_2dG_arr_y2,'\\n')\n",
    "\n",
    "# # index_nine = 3 #box size 9\n",
    "\n",
    "# # index_fifteen = 6  #box size 15\n",
    "# # radius = int(box_size_arr[index_nine])\n",
    "# radius = 13\n",
    "# val_2dg_x = centroid_2dG_arr_x2[14]\n",
    "# val_2dg_y = centroid_2dG_arr_y2[14]\n",
    "\n",
    "# print(radius,val_2dg_x,val_2dg_y)\n",
    "\n",
    "\n",
    "# for positions we will take the 2dg Gaussian outputs.\n",
    "\n",
    "positions = [(val_2dg_x, val_2dg_y)]\n",
    "apertures = CircularAperture(positions, r=radius)\n",
    "print(apertures)\n",
    "\n",
    "phot_table = aperture_photometry(counts_image[0,:,:],apertures)\n",
    "print(phot_table,'\\n')\n",
    "\n",
    "# another aperture radius \n",
    "\n",
    "radius = 20\n",
    "val_2dg_x = centroid_2dG_arr_x2[14]\n",
    "val_2dg_y = centroid_2dG_arr_y2[14]\n",
    "\n",
    "print(radius,val_2dg_x)\n",
    "apert_sum_r3 = 385848.1178699848\n",
    "apert_sum_r2 = 311819.7046191514\n",
    "num = -apert_sum_r3 + apert_sum_r2\n",
    "# print(num)\n",
    "\n",
    "radius =np.linspace(1,15,15)\n",
    "# radius\n",
    "\n",
    "# find the photometry within the aperture. we are taking \n",
    "# backrground pixel of the flux and will be trying to add \n",
    "# it back in (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another aperture radius \n",
    "\n",
    "radius = 13\n",
    "val_2dg_x = centroid_2dG_arr_x2[14]\n",
    "val_2dg_y = centroid_2dG_arr_y2[14]\n",
    "\n",
    "print(radius,val_2dg_x,val_2dg_y)\n",
    "\n",
    "\n",
    "# for positions we will take the 2dg Gaussian outputs.\n",
    "\n",
    "positions = [(val_2dg_x, val_2dg_y)]\n",
    "apertures = CircularAperture(positions, r=radius)\n",
    "print(apertures)\n",
    "\n",
    "phot_table = aperture_photometry(counts_image[0,:,:],apertures)\n",
    "print(phot_table)\n",
    "\n",
    "apert_sum_r3 = 385848.1178699848\n",
    "apert_sum_r2 = 311819.7046191514\n",
    "num = -apert_sum_r3 + apert_sum_r2\n",
    "# print(num)\n",
    "\n",
    "radius =np.linspace(1,15,15)\n",
    "# radius\n",
    "\n",
    "# find the photometry within the aperture. we are taking \n",
    "# backrground pixel of the flux and will be trying to add \n",
    "# it back in (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import CircularAperture\n",
    "from photutils import aperture_photometry\n",
    "\n",
    "# print(box_size_arr,'\\n')\n",
    "# print(centroid_2dG_arr_x2,'\\n')\n",
    "# print(centroid_2dG_arr_y2,'\\n')\n",
    "\n",
    "# index_nine = 3 #box size 9\n",
    "\n",
    "# index_fifteen = 6  #box size 15\n",
    "# radius = int(box_size_arr[index_nine])\n",
    "# radius = 13\n",
    "# val_2dg_x = centroid_2dG_arr_x2[14]\n",
    "# val_2dg_y = centroid_2dG_arr_y2[14]\n",
    "\n",
    "# # print(radius,val_2dg_x,val_2dg_y)\n",
    "\n",
    "\n",
    "# # for positions we will take the 2dg Gaussian outputs.\n",
    "\n",
    "# positions = [(val_2dg_x, val_2dg_y)]\n",
    "# apertures = CircularAperture(positions, r=radius)\n",
    "# print(apertures)\n",
    "\n",
    "# phot_table = aperture_photometry(counts_image[0,:,:],apertures)\n",
    "# print(phot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from photutils import CircularAperture\n",
    "# from photutils import aperture_photometry\n",
    "\n",
    "# # print(box_size_arr,'\\n')\n",
    "# # print(centroid_2dG_arr_x2,'\\n')\n",
    "# # print(centroid_2dG_arr_y2,'\\n')\n",
    "\n",
    "# # index_nine = 3 #box size 9\n",
    "\n",
    "# # index_fifteen = 6  #box size 15\n",
    "# # radius = int(box_size_arr[index_nine])\n",
    "# radius = 13\n",
    "# val_2dg_x = centroid_2dG_arr_x2[14]\n",
    "# val_2dg_y = centroid_2dG_arr_y2[14]\n",
    "\n",
    "# print(radius,val_2dg_x,val_2dg_y)\n",
    "\n",
    "\n",
    "# # for positions we will take the 2dg Gaussian outputs.\n",
    "\n",
    "# positions = [(val_2dg_x, val_2dg_y)]\n",
    "# apertures = CircularAperture(positions, r=radius)\n",
    "# print(apertures)\n",
    "\n",
    "# phot_table = aperture_photometry(counts_image[0,:,:],apertures)\n",
    "# print(phot_table)\n",
    "\n",
    "# # another aperture radius \n",
    "\n",
    "# ---\\\n",
    "# radius = 20\n",
    "# val_2dg_x = centroid_2dG_arr_x2[14]\n",
    "# # val_2dg_y = centroid_2dG_arr_y2[14]\n",
    "\n",
    "# # print(radius,val_2dg_x,val_2dg_y)\n",
    "\n",
    "\n",
    "# # # for positions we will take the 2dg Gaussian outputs.\n",
    "\n",
    "# # positions = [(val_2dg_x, val_2dg_y)]\n",
    "# # apertures = CircularAperture(positions, r=radius)\n",
    "# # print(apertures)\n",
    "\n",
    "# # phot_table = aperture_photometry(counts_image[0,:,:],apertures)\n",
    "# # print(phot_table)\n",
    "# --\n",
    "\n",
    "# apert_sum_r3 = 385848.1178699848\n",
    "# apert_sum_r2 = 311819.7046191514\n",
    "# num = -apert_sum_r3 + apert_sum_r2\n",
    "# # print(num)\n",
    "\n",
    "# radius =np.linspace(1,15,15)\n",
    "# # radius\n",
    "\n",
    "# # find the photometry within the aperture. we are taking \n",
    "# # backrground pixel of the flux and will be trying to add \n",
    "# # it back in (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'radius_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-41066c040948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mradius_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbackgrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0map_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0map_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mradius_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#         print(backgrnd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbackgrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackgrnd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'radius_arr' is not defined"
     ]
    }
   ],
   "source": [
    "for j in radius_arr:\n",
    "    if k ==0:\n",
    "        backgrnd = (ap_arr[0] - ap_arr[0]) / (math.pi*(radius_arr[0]**2 - radius_arr[k]**2)) \n",
    "#         print(backgrnd)\n",
    "        backgrnd = backgrnd + add\n",
    "        k = 1+k\n",
    "        b_arr.append(backgrnd)\n",
    "    elif k > 0:\n",
    "        backgrnd = (ap_arr[0] - ap_arr[k]) / (math.pi*(radius_arr[0]**2 - radius_arr[k]**2))\n",
    "#         print(backgrnd)\n",
    "        backgrnd = backgrnd + add\n",
    "        k = 1+k\n",
    "        b_arr.append(backgrnd)\n",
    "print(ap_arr)\n",
    "\n",
    "for j in radius_arr:\n",
    "    if k ==0:\n",
    "        backgrnd = (ap_arr[1] - ap_arr[0]) / (math.pi*(radius_arr[1]**2 - radius_arr[0]**2)) \n",
    "#         print(backgrnd)\n",
    "        backgrnd = backgrnd + add\n",
    "        k = 1+k\n",
    "        b_arr.append(backgrnd)\n",
    "    elif k > 0:\n",
    "        backgrnd = (ap_arr[k] - ap_arr[0]) / (math.pi*(radius_arr[k]**2 - radius_arr[0]**2))\n",
    "#         print(backgrnd)\n",
    "        backgrnd = backgrnd + add\n",
    "        k = 1+k\n",
    "        b_arr.append(backgrnd)\n",
    "print(ap_arr)\n",
    "print( b_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # npix = 32\n",
    "# # box = 29\n",
    "# # result= (npix - box)/2\n",
    "# # if result % 1 == 0:\n",
    "# #     end_num = round(result,0)\n",
    "# #     strt_num = end_num\n",
    "# #     new_st = strt_num\n",
    "# #     new_end = npix - end_num\n",
    "# # else:\n",
    "# #     end_num = round(result,0)\n",
    "# #     strt_num = end_num - 1 \n",
    "# #     new_st = strt_num \n",
    "# #     new_end = npix - end_num\n",
    "# # print(result,'\\n',strt_num,end_num,'\\n',new_st,new_end)\n",
    "\n",
    "# # ----\n",
    "# # fig, ax = plt.subplots(1, 1)\n",
    "# # ax.imshow(counts_image[:][:][1], norm=LogNorm())\n",
    "# # plt.ylim(10,20)\n",
    "# # plt.xlim(10,20)\n",
    "# # plt.plot(x1[0],y1[0])\n",
    "\n",
    "# # new_array = counts_image[10:20][10:20][1]\n",
    "# # print(counts_image[:][:][1])\n",
    "# # print(new_array)\n",
    "\n",
    "# ---\n",
    "# # print(x1,y1)\n",
    "\n",
    "# #print(x1[0],y1[0])\n",
    "# # print(counts_image[:][:][0])\n",
    "\n",
    "# # for i in range(len(counts_image)):\n",
    "# #     for j in range(len(counts_image[i])):\n",
    "# ---\n",
    "# # x, y = np.meshgrid(counts_image[0,:,:],counts_image[0,:,:])\n",
    "# # # x, y = np.meshgrid(np.linspace(-1,1,10), np.linspace(-1,1,10))\n",
    "# # d = np.sqrt(x*x+y*y)\n",
    "# # sigma, mu = 1.0, 0.0\n",
    "# # g = np.exp(-( (d-mu)**2 / ( 2.0 * sigma**2 ) ) )\n",
    "# # plt.plot(g,'.')\n",
    "# # print(\"2D Gaussian-like array:\")\n",
    "# # # print(g)\n",
    "# # plt.xlim(362,365)\n",
    "# ---\n",
    "# # results = guass_params()\n",
    "# # results.\n",
    "# # x_stddev = -0.57418303\n",
    "# # y_stddev = -0.75556257\n",
    "# # FWHM =2.35*(guass_params.x_stddev+guass_params.y_stddev)/2\n",
    "# # print(FWHM)\n",
    "\n",
    "\n",
    "\n",
    "# ------\n",
    "# # plt.plot(radial_prof,label='COM (blue)')\n",
    "# # plt.plot(radial_prof_2,label='Gaussian (orange)')\n",
    "# --\n",
    "# # strt,end = slicing_im(32,9)\n",
    "# # im2 = counts_image[0,strt:end,strt:end] \n",
    "# # plt.imshow(im2)\n",
    "# ---\n",
    "# # i =0\n",
    "# # new_arr =[]\n",
    "# # for i in range(len(centroid_com_arr_x1)):\n",
    "# #     result = centroid_com_arr_x1[i]-i-1\n",
    "# #     new_arr.append(result)\n",
    "# # #     print(result)\n",
    "# # new_arr\n",
    "# # # ----------------------------Edit this one\n",
    "# # scale_num = 100\n",
    "# # COM_arr_x=[]\n",
    "# # npix = 32\n",
    "# # start_i = 3\n",
    "# # steps_i = 2\n",
    "# # time_i = 0\n",
    "# # dictionary = {'centroid_com_arr_x_'+str(time_i):[],\n",
    "# #               'centroid_com_arr_y_'+str(time_i):[],\n",
    "# #               'centroid_2dG_arr_x_'+str(time_i):[],\n",
    "# #               'centroid_2dG_arr_y_'+str(time_i):[]}\n",
    "# # j = 0\n",
    "# # j = j+1\n",
    "# # for time_i in range(0,3):\n",
    "# #     print(time_i)\n",
    "# # #     print(dictionary['centroid_com_arr_x_'+str(time_i)])\n",
    "# #     for i_box in range(start_i,npix,steps_i):\n",
    "# #         strt, end = slicing_im(npix,i_box)\n",
    "# #         interval = PercentileInterval(scale_num) ###\n",
    "# #         interval.get_limits(counts_image[time_i,strt:end,strt:end])\n",
    "# #         scale_array = interval(counts_image[time_i,strt:end,strt:end])\n",
    "# # #         sliced_image = counts_image[0,strt:end,strt:end] \n",
    "# #         result = scale_array\n",
    "# #         if i_box < 3:\n",
    "# #             print('too small of an imgae to calculate\\n')\n",
    "# #         elif i_box >= 3:\n",
    "# #             x1, y1 = centroid_com(result)\n",
    "# #             x2, y2 = centroid_2dg(result)\n",
    "# # #             print(i_box,strt,end)\n",
    "# # #             print('Box Size: ', i_box,'x',i_box)\n",
    "# # #             print('COM: ',x1,y1)\n",
    "# # #             print('2dG: ',x2,y2,'\\n')\n",
    "# #         dictionary['centroid_com_arr_x_'+str(time_i)].append(x1)\n",
    "# #         dictionary['centroid_com_arr_y_'+str(time_i)].append(y1)\n",
    "# #         dictionary['centroid_2dG_arr_x_'+str(time_i)].append(x2)\n",
    "# #         dictionary['centroid_2dG_arr_y_'+str(time_i)].append(y2)\n",
    "# # #         plt.imshow(result)\n",
    "# # #         plt.show()  \n",
    "# # print('Done.')\n",
    "# # str_1='centroid_com_arr_x_'\n",
    "# # str_2='centroid_com_arr_y_'\n",
    "# # str_3='centroid_2dG_arr_x_'\n",
    "# # str_4='centroid_2dG_arr_y_'\n",
    "\n",
    "# # jump_i =0\n",
    "# # dictionary = {}\n",
    "# # def dict_loop(one):\n",
    "# #     for i in range(0,1):\n",
    "# #         str_n = str(i)\n",
    "# #         dictionary[one+str_n] =[]\n",
    "# # #         jumo_i = jump_i+1\n",
    "# #     return dictionary\n",
    "\n",
    "# # # print(dictionary)\n",
    "# # dict_loop(str_1)\n",
    "# # print(dictionary)# time_i = 2\n",
    "# # # print(dictionary)\n",
    "# ----\n",
    "# # empty_dict\n",
    "# # ------------------\n",
    "\n",
    "\n",
    "# # def array_splitter(list_arr,str_name,start_index,end_index,total_num):\n",
    "# #     start_ind =start_index #suggested to start ar index zero\n",
    "# #     end_ind = end_index\n",
    "# #     name_of_var = str(str_name)\n",
    "# #     empty_dict = {}\n",
    "# #     for i in range(0,total_num):\n",
    "# #         empty_dict[name_of_var+'_'+str(i)] = list_arr[start_ind:end_ind]\n",
    "# #         start_ind = start_ind + end_ind\n",
    "# #         end_ind = end_ind+end_ind\n",
    "# #     return empty_dict\n",
    "# # # ---------\n",
    "\n",
    "\n",
    "# # example = array_splitter(centroid_com_arr_x,\"CEN_COM_X\",0,15,64)\n",
    "\n",
    "# # # print(example['CEN_COM_X_5'])\n",
    "# # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_arr =os.listdir(ori_dir)\n",
    "\n",
    "# dir_bcd_arr =[]\n",
    "# sudir=[]\n",
    "\n",
    "# del dir_arr[0:1]\n",
    "# for i in dir_arr:\n",
    "#     dir_fullName = os.path.join(ori_dir,i)\n",
    "#     dir_bcd_arr.append(dir_fullName)\n",
    "# dir_bcd_arr\n",
    "\n",
    "# # count = 0\n",
    "# # for i in dir_bcd_arr:\n",
    "# # #     print(i)\n",
    "# #     for x in os.listdir(dir_bcd_arr[0]):\n",
    "# #         print(x)\n",
    "\n",
    "    \n",
    "# # # bcd list arrays\n",
    "# # dir_bcd_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(counts_image[l,:,:])\n",
    "# print(dict_cen[str_num_arr[2]])\n",
    "# print(str_num_arr)\n",
    "# print(time_arr)\n",
    "# print(time_arr)\n",
    "# np.savetxt('file.txt', np.column_stack([a]),fmt='%.3f', delimiter=' ',newline=os.linesep)\n",
    "\n",
    "# an_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_data/'\n",
    "# an0 = 'Ap_phot_part_1' \n",
    "# an1 = '.txt'\n",
    "# an = [an_dir,an0,an1]\n",
    "# an_str = \"\".join(str(t) for t in an)\n",
    "# Int = Table([test_1], names=['Aperture_Phot'])\n",
    "# ascii.write(Int, an_str, format='tab', fast_writer=False) \n",
    "\n",
    "# for n_index in range(8):\n",
    "# #     num = [1,2,3,4,5,6,7]\n",
    "#     if n_index == 5:\n",
    "#         part_inp = str(6)\n",
    "#         part_num =\"_part_\"+part_inp+\"-1\"\n",
    "#     elif n_index == 6:\n",
    "#         part_inp = str(6)\n",
    "#         part_num =\"_part_\"+part_inp+\"-2\"\n",
    "#     elif n_index == 7:\n",
    "#         part_inp = str(7)\n",
    "#         part_num =\"_part_\"+part_inp\n",
    "#     else:\n",
    "#         part_inp = str(num[n_index])\n",
    "#         part_num =\"_part_\"+part_inp\n",
    "#     des_var_dir = \"only_\"+ desired_var + part_num\n",
    "#     created_dir = \"/Users/melaniapena/Rsrch/Luhman_16_Research/bcd_files/\" \n",
    "#     save_dir = created_dir + des_var_dir\n",
    "#     print(\"Created directory:\",save_dir)\n",
    "#     if not os.path.exists(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "\n",
    "# new_dir_arr=[]\n",
    "# for n_index in range(8):\n",
    "#     num = [1,2,3,4,5,6,7]\n",
    "#     if n_index == 5:\n",
    "#         part_inp = str(6)\n",
    "#         part_num =\"ap_ph_prt_\"+part_inp+\"-1\"\n",
    "#     elif n_index == 6:\n",
    "#         part_inp = str(6)\n",
    "#         part_num =\"ap_ph_prt_\"+part_inp+\"-2\"\n",
    "#     elif n_index == 7:\n",
    "#         part_inp = str(7)\n",
    "#         part_num =\"ap_ph_prt_\"+part_inp\n",
    "#     else:\n",
    "#         part_inp = str(num[n_index])\n",
    "#         part_num =\"ap_ph_prt_\"+part_inp\n",
    "#     des_var_dir = part_num\n",
    "#     created_dir = \"/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/\" \n",
    "#     save_dir = created_dir + des_var_dir\n",
    "# #     print(\"Created directory:\",save_dir)\n",
    "\n",
    "#     if not os.path.exists(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "#         new_dir_arr.append(save_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part_num=str(1)\n",
    "# ori_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_'+part_num+'/' \n",
    "# # num_str = [1,2,3,4,5,6,7]\n",
    "# # ori_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_'+str(num_str[part_num])+'/' \n",
    "# # word='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_1/Ap_phot_part_1.txt'\n",
    "# # data_ascii = ascii.read(word)\n",
    "# # flux = data_ascii[col_1]\n",
    "# # # print(bmjd_HST)\n",
    "# # plt.ylim([450000,480000])\n",
    "# # plt.plot(flux)\n",
    "# ind_time_arr = []\n",
    "\n",
    "# frameday = frame_t/(3600*24)\n",
    "# shift_bmjd = bmjd_obs + 0.5* frameday\n",
    "# ind_time_arr.append(shift_bmjd)\n",
    "# # print(ind_time_arr)\n",
    "# j_final = 63\n",
    "# for j in range(len(photometry_arr)-1):\n",
    "#     value = ind_time_arr[0] + (j+1)*frameday\n",
    "#     bmjd_arr = ind_time_arr.append(value)\n",
    "# # time_arr = npa.linspace(0,63,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_part1='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_1/Ap_phot_part_1.txt'\n",
    "# t_part1='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_1/bcdfits_time_prt_1.txt'\n",
    "# data_ascii = ascii.read(ori_part1)\n",
    "# t_ascii = ascii.read(t_part1)\n",
    "# fl= data_ascii['Aperture_Phot']\n",
    "# t= t_ascii['col_1']\n",
    "# plt.plot(t,fl)\n",
    "\n",
    "# frameday = frame_t/(3600*24)\n",
    "# shift_bmjd = bmjd_obs + 0.5* frameday\n",
    "# list_bmjd =[shift_bmjd]\n",
    "# for j in range(len(phot_ap_arr)-1):\n",
    "#     value = list_bmjd[0] + (j+1)*frameday\n",
    "#     list_bmjd.append(value)\n",
    "# print(list_bmjd)\n",
    "\n",
    "\n",
    "# word='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_3/t_array.txt'\n",
    "# Tot_arr = Table([list_bmjd], names=['T_prt3'])\n",
    "# ascii.write(Tot_arr, word, format='tab', fast_writer=False)\n",
    "\n",
    "\n",
    "# plt.plot(list_bmjd,phot_ap_arr,'b')\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plottting only \n",
    "# # plt.xlim([0,20000])\n",
    "\n",
    "# frame_t = fits_file[0].header['FRAMTIME']\n",
    "# bmjd_obs = fits_file[0].header['BMJD_OBS']\n",
    "# # print('bmjd observation:', bmjd_obs)\n",
    "# flux_conv= fits_file[0].header['FLUXCONV']\n",
    "# # print('Flux Conversion',flux_conv)\n",
    "# gain = fits_file[0].header['GAIN']\n",
    "# # print('Gain',gain)\n",
    "# exp_time= fits_file[0].header['EXPTIME']\n",
    "\n",
    "# # print('Exp-time', exp_time)\n",
    "# # frameday = frame_t/(3600*24)\n",
    "# # shift_bmjd = bmjd_obs + 0.5* frameday\n",
    "# # list_bmjd =[shift_bmjd]\n",
    "# # for j in range(len(phot_ap_arr)-1):\n",
    "# #     value = list_bmjd[0] + (j+1)*frameday\n",
    "# #     list_bmjd.append(value)\n",
    "\n",
    "# t_part1='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_3/bcdfits_time_prt_3.txt'\n",
    "# t_ascii = ascii.read(t_part1)\n",
    "# t_3= t_ascii['T_prt3']\n",
    "# plt.ylim([450000,480000])\n",
    "# plt.plot(t_3,phot_ap_arr,'g')\n",
    "\n",
    "# # -------------\n",
    "# ori_part1='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_1/Ap_phot_part_1.txt'\n",
    "# t_part1='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_1/bcdfits_time_prt_1.txt'\n",
    "# data_ascii = ascii.read(ori_part1)\n",
    "# t_ascii = ascii.read(t_part1)\n",
    "# fl= data_ascii['Aperture_Phot']\n",
    "# t_1= t_ascii['col_1']\n",
    "# plt.ylim([450000,480000])\n",
    "# plt.plot(_1,fl)\n",
    "# # --------------------\n",
    "# # plt.ylim([450000,480000])\n",
    "# # plt.plot(t_1,fl)\n",
    "# # plt.plot(t_3,phot_ap_arr,'g')\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from astropy.io import ascii\n",
    "# from astropy.table import Table, Column, MaskedColumn\n",
    "# lightcurve_1='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_1/Ap_phot_part_1.txt'\n",
    "# lightcurve_3='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_3/Ap_phot_part_3.txt'\n",
    "# time1='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_1/bcdfits_time_prt_1.txt'\n",
    "# time3='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_3/bcdfits_time_prt_3.txt'\n",
    "# data_1 = ascii.read(lightcurve_1)\n",
    "# data_3 = ascii.read(lightcurve_3)\n",
    "# t_1=ascii.read(time1)\n",
    "# t_3=ascii.read(time3)\n",
    "# plt.plot(t_1,data_1,'.',label='Part 1')\n",
    "# plt.plot(t_3,data_3,'.', label='Part 3')\n",
    "# plt.ylim([450000,490000])\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Light Curve')\n",
    "# # plt.show()\n",
    "# plt.savefig('F-vs-T(prt1-and-prt3)_full.png')\n",
    "\n",
    "# ----\n",
    "# def time_arr(time_arr,ind_time_arr,part_num,frame_t,bmjd_obs)\n",
    "#     frameday = frame_t/(3600*24)\n",
    "#     if part_num==1:\n",
    "# #         there'll be a slight shift.\n",
    "#         shift_bmjd= bmjd_obs+0.5*frameday\n",
    "#         time_arr.append(shift_bmjd)\n",
    "#         ind_time_arr.append(shift_bmjd)\n",
    "#         for j in range(63):\n",
    "#             value = time_arr[0] + (j+1)*frameday\n",
    "#             bmjd_arr = ind_time_arr.append(value)\n",
    "#             time_arr.append(value)\n",
    "#     else:\n",
    "#         for j in range(63):\n",
    "#             value=time\n",
    "            \n",
    "# #         ---------------------------------------------\n",
    "        \n",
    "#         if not time_arr:\n",
    "#             frameday = frame_t/(3600*24)\n",
    "#             shift_bmjd = bmjd_obs + 0.5* frameday\n",
    "#             time_arr.append(shift_bmjd)\n",
    "#             ind_time_arr.append(shift_bmjd)\n",
    "#             for j in range(63):\n",
    "#                 value = time_arr[0] + (j+1)*frameday\n",
    "#                 bmjd_arr = ind_time_arr.append(value)\n",
    "#                 time_arr.append(value)\n",
    "#         else:\n",
    "#             j_final = 63\n",
    "#             for j in range(63):\n",
    "#                 frameday = frame_t/(3600*24)\n",
    "#                 value = time_arr[0] + (j+1)*frameday\n",
    "#                 bmjd_arr = ind_time_arr.append(value)\n",
    "#                 time_arr.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         -----\n",
    "#         if n_index == 5:\n",
    "#             part_inp = str(6)\n",
    "#             part_num =name_of_file_last+part_inp+\"-1\"\n",
    "#         if n_index == 6:\n",
    "#             numb = np.insert(numb,5,6)\n",
    "#             part_inp = str(6)\n",
    "#             if l == 0:\n",
    "#                 part_num = name_of_file_last+part_inp+\"-1\"\n",
    "#             else:\n",
    "#                 part_num =name_of_file_last+part_inp+\"-2\"\n",
    "                \n",
    "#         elif n_index == 7:\n",
    "#             part_inp = str(7)\n",
    "#             part_num =name_of_file_last+part_inp\n",
    "#         else:\n",
    "#             part_inp = str(int(numb[n_index-1]))\n",
    "#             print(part_inp)\n",
    "#             part_num = name_of_file_last+part_inp\n",
    "#         save_dir = created_dir + part_num        \n",
    "# #         -----\n",
    "# part of folder organizer def\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### single fmlp\n",
    "## NOTE: This bottom code will be used later on for only com centroids\n",
    "# def org_dict(dict_name,str_num_name,com_x,com_y):\n",
    "#     start_ind =0 \n",
    "#     end_ind = 15 \n",
    "#     str_arr_list = [\"cen_com_arr_x\", \"cen_com_arr_y\"]\n",
    "#     dict_cen = dict_name\n",
    "# # puts each into a seperate array of 15 indexes\n",
    "#     for i in range(0,64):\n",
    "#         dict_cen[str_arr_list[0]+'_'+str(i)] = com_x[start_ind:end_ind]\n",
    "#         dict_cen[str_arr_list[1]+'_'+str(i)] = com_y[start_ind:end_ind]\n",
    "#         start_ind = start_ind + 15\n",
    "#         end_ind = end_ind+15\n",
    "# #creates an array of numbered names.\n",
    "#     str_num_arr=str_num_name\n",
    "#     for j in range(0,64):\n",
    "#         str_name_1 = str_arr_list[0]+'_'+str(j)\n",
    "#         str_name_2 = str_arr_list[1]+'_'+str(j)\n",
    "#         str_num_arr.append(str_name_1)\n",
    "#         str_num_arr.append(str_name_2)\n",
    "\n",
    "        \n",
    "# str_num_arr=[]      \n",
    "# dict_cen = {}\n",
    "# org_dict(dict_cen,str_num_arr,centroid_com_arr_x,centroid_com_arr_y)\n",
    "         \n",
    "# dict_cen\n",
    "# test\n",
    "# print(dict_cen['cen_com_arr_x_1'][0])\n",
    "# print(dict_cen['cen_com_arr_y_1'][0])\n",
    "# print(dict_cen['cen_2dg_arr_x_1'][0])\n",
    "# print(dict_cen['cen_2dg_arr_y_1'][0])\n",
    "# ----------------------------------------------------------------------\n",
    "# r_1 = 6\n",
    "# r_2 = 12\n",
    "# r_3 = 14\n",
    "# h_com = 0 ##index for com (only for com index)\n",
    "# photometry_arr =[]\n",
    "# for l in range(0,64):\n",
    "#     aperture_1 = aperture_sum(r_1,counts_image[l,:,:], dict_cen[str_num_arr[h_com]][14], dict_cen[str_num_arr[h_com+1]][14]) \n",
    "#     aperture_2 = aperture_sum(r_2,counts_image[l,:,:], dict_cen[str_num_arr[h_com]][14], dict_cen[str_num_arr[h_com+1]][14])\n",
    "#     aperture_3 = aperture_sum(r_3,counts_image[l,:,:], dict_cen[str_num_arr[h_com]][14], dict_cen[str_num_arr[h_com+1]][14])\n",
    "    \n",
    "# ## Area of aperture,\n",
    "#     area_1 = math.pi * r_1**2\n",
    "\n",
    "# ## Background in annulus from r_2 to r_3\n",
    "#     background_counts = aperture_3 - aperture_2\n",
    "\n",
    "# ## Area of Annulus\n",
    "#     area_2 = math.pi*(r_3**2 - r_2**2) #also known as npix\n",
    "\n",
    "# ## subtracting background: \n",
    "#     backgrnd_subtract = aperture_1 - background_counts*area_1/area_2\n",
    "#     photometry_arr.append(backgrnd_subtract)\n",
    "# #     h = h+4\n",
    "#     h_com = h_com+2\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# if part_num==6:\n",
    "#     ori_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_6-1/'\n",
    "# elif part_num==7:\n",
    "#     ori_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_6-2/'\n",
    "# elif part_num==8:\n",
    "#     ori_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_7/'\n",
    "# else:\n",
    "#     ori_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii/ap_ph_prt_'+str(part_num)+'/'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfmp\n",
    "## NOTE: this bottom code will be used later on\n",
    "# for time_i in range(0,64):        \n",
    "#     for i_box in range(start_i,npix,steps_i):\n",
    "#         strt, end = slicing_im(npix,i_box)\n",
    "#         interval = PercentileInterval(scale_num) ###\n",
    "#         interval.get_limits(counts_image[time_i,strt:end,strt:end])\n",
    "#         scale_array = interval(counts_image[time_i,strt:end,strt:end])\n",
    "#         sliced_image = counts_image[0,strt:end,strt:end] \n",
    "#         result = scale_array\n",
    "#         if i_box < 3:\n",
    "#             print('too small of an image to calculate\\n')\n",
    "#         elif i_box >= 3:\n",
    "#             x1, y1 = centroid_com(result)\n",
    "# #             x2, y2 = centroid_2dg(result) Takes too long to process\n",
    "#             print(i_box,strt,end)\n",
    "#             print('Box Size: ', i_box,'x',i_box)\n",
    "#             print('COM: ',x1,y1)\n",
    "# #             print('2dG: ',x2,y2)\n",
    "#             centroid_com_arr_x.append(x1)\n",
    "#             centroid_com_arr_y.append(y1)\n",
    "# #             centroid_2dG_arr_x.append(x2) The x and y conetroids for 2dg takes\n",
    "# #             centroid_2dG_arr_y.append(y2) too long to process makinf the whole code \n",
    "# #                                           a lot longer than necassary\n",
    "#             num = num+1\n",
    "#             print(num,time_i,'\\n')\n",
    "# #             plt.imshow(result)\n",
    "# #             plt.show()\n",
    "# ======\n",
    "## Singular spaced out code before making it into a definition function\n",
    "\n",
    "# start_ind =0 \n",
    "# end_ind = 15\n",
    "# str_arr_list = [\"cen_com_arr_x\", \"cen_com_arr_y\",\"cen_2dg_arr_x\",\"cen_2dg_arr_y\"]\n",
    "# dict_cen = {}\n",
    "# # puts each into a seperate array of 15 indexes\n",
    "# for i in range(0,64):\n",
    "#     dict_cen[str_arr_list[0]+'_'+str(i)] = centroid_com_arr_x[start_ind:end_ind]\n",
    "#     dict_cen[str_arr_list[1]+'_'+str(i)] = centroid_com_arr_y[start_ind:end_ind]\n",
    "#     dict_cen[str_arr_list[2]+'_'+str(i)] = centroid_2dG_arr_x[start_ind:end_ind]\n",
    "#     dict_cen[str_arr_list[3]+'_'+str(i)] = centroid_2dG_arr_y[start_ind:end_ind]\n",
    "#     start_ind = start_ind + 15\n",
    "#     end_ind = end_ind+15\n",
    "\n",
    "# #creates an array of numbered names.\n",
    "# str_num_arr=[]\n",
    "# for j in range(0,64):\n",
    "#     str_name_1 = str_arr_list[0]+'_'+str(j)\n",
    "#     str_name_2 = str_arr_list[1]+'_'+str(j)\n",
    "#     str_name_3 = str_arr_list[2]+'_'+str(j)\n",
    "#     str_name_4 = str_arr_list[3]+'_'+str(j)\n",
    "#     str_num_arr.append(str_name_1)\n",
    "#     str_num_arr.append(str_name_2)\n",
    "#     str_num_arr.append(str_name_3)\n",
    "#     str_num_arr.append(str_name_4)\n",
    "#//--------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         scale_num = 100\n",
    "#         npix = 32\n",
    "#         start_i = 3\n",
    "#         steps_i = 2\n",
    "#         -----------------------------------------------\n",
    "#         Finds the Centroids from the various sliced images\n",
    "\n",
    "#         for time_i in range(0,64):        \n",
    "#             for i_box in range(start_i,npix,steps_i):\n",
    "#                 strt, end = slicing_im(npix,i_box)\n",
    "#                 interval = PercentileInterval(scale_num) ###\n",
    "#                 interval.get_limits(counts_image[time_i,strt:end,strt:end])\n",
    "#                 scale_array = interval(counts_image[time_i,strt:end,strt:end])\n",
    "#                 sliced_image = counts_image[0,strt:end,strt:end] \n",
    "#                 result = scale_array\n",
    "#                 if i_box < 3:\n",
    "#                     print('too small of an image to calculate\\n')\n",
    "#                 elif i_box >= 3:\n",
    "#                     x1, y1 = centroid_com(result)\n",
    "#                     centroid_com_arr_x.append(x1)\n",
    "#                     centroid_com_arr_y.append(y1)\n",
    "# #                     print(i_box,strt,end)\n",
    "# #                     print('Box Size: ', i_box,'x',i_box)\n",
    "# #                     print('COM: ',x1,y1)\n",
    "# #                     print('2dG: ',x2,y2)\n",
    "#                     if i_box == 15:\n",
    "#                         centroid_com_arr_x1.append(x1)\n",
    "#                         centroid_com_arr_y1.append(y1)\n",
    "#                         cen_com_arr_x.append(x1)\n",
    "#                         cen_com_arr_y.append(y1)\n",
    "#                     num = num+1\n",
    "# #                     print(num,time_i,'\\n')\n",
    "# #                     plt.imshow(result)\n",
    "# #                     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightcurve_compare2='/Users/melaniapena/Rsrch/Luhman_16_Research/2ap_phot_ascii_com/com_ap_ph_prt1/bcdfits_part_1.txt'\n",
    "# lightcurve_compare3='/Users/melaniapena/Rsrch/Luhman_16_Research/3ap_phot_ascii_com/com_ap_ph_prt1/bcdfits_part_1.txt'\n",
    "# lightcurve_compare4='/Users/melaniapena/Rsrch/Luhman_16_Research/4ap_phot_ascii_com/com_ap_ph_prt1/bcdfits_part_1.txt'\n",
    "# lightcurve_compare5='/Users/melaniapena/Rsrch/Luhman_16_Research/5ap_phot_ascii_com/com_ap_ph_prt1/bcdfits_part_1.txt'\n",
    "# lightcurve_compare6='/Users/melaniapena/Rsrch/Luhman_16_Research/6ap_phot_ascii_com/com_ap_ph_prt1/bcdfits_part_1.txt'\n",
    "# lightcurve_compare7='/Users/melaniapena/Rsrch/Luhman_16_Research/7ap_phot_ascii_com/com_ap_ph_prt1/bcdfits_part_1.txt'\n",
    "# lightcurve_compare8='/Users/melaniapena/Rsrch/Luhman_16_Research/8ap_phot_ascii_com/com_ap_ph_prt1/bcdfits_part_1.txt'\n",
    "# lightcurve_compare9='/Users/melaniapena/Rsrch/Luhman_16_Research/tst1ap_phot_ascii_2dg/dg_ap_ph_prt1/bcdfits_part_1.txt'\n",
    "\n",
    "\n",
    "# c_data = ascii.read(lightcurve_compare)\n",
    "# c3_data = ascii.read(lightcurve_compare3)\n",
    "# c_ap= c_data[col_1]\n",
    "# c_bmjd = c_data[col_2]\n",
    "# c3_ap= c3_data[col_1]\n",
    "# c3_bmjd = c3_data[col_2]\n",
    "# plt.plot(c3_bmjd,c3_ap,'.',label='compare')\n",
    "# plt.plot(c_bmjd,c_ap,'.',label='compare')\n",
    "\n",
    "# plt.ylim([0.,2.5])\n",
    "# plt.ylim([-25000,25000])\n",
    "# lc=plot_ascii(lightcurve_1,col_1,col_2,'8-13-23 31x31')\n",
    "# lc2=plot_ascii(lightcurve_compare2,col_1,col_2,'7-11-14 31x31')\n",
    "\n",
    "# lc3=plot_ascii(lightcurve_compare3,col_1,col_2,'8-13-23 7x7') #Causes the light curve appear spread out\n",
    "# lc4=plot_ascii(lightcurve_compare4,col_1,col_2,'8-13-23 9x9 ')#looks even more spread out.\n",
    "\n",
    "# lc5=plot_ascii(lightcurve_compare5,col_1,col_2,'7-11-14 7x7')#Really spread out, gives that extra line at the bottom \n",
    "# lc6=plot_ascii(lightcurve_compare6,col_1,col_2,'7-11-14 9x9') # thinner but same form, gives extra line\n",
    "\n",
    "# lc7=plot_ascii(lightcurve_compare7,col_1,col_2,'7-11-14 at 23x23') \n",
    "# lc8=plot_ascii(lightcurve_compare8,col_1,col_2,'7-11-14 at 7x7')\n",
    "# lc9=plot_ascii(lightcurve_compare9,col_1,col_2,'2dg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         centroid_2dg_arr_xtot=[]\n",
    "#         centroid_2dg_arr_ytot=[]\n",
    "        \n",
    "#         scale_num = 100\n",
    "#         npix = 32\n",
    "#         start_i = 3\n",
    "#         steps_i = 2\n",
    "#         -----------------------------------------------\n",
    "#         Finds the Centroids from the various sliced images\n",
    "\n",
    "#         for time_i in range(0,64):        \n",
    "#             for i_box in range(start_i,npix,steps_i):\n",
    "#                 strt, end = slicing_im(npix,i_box)\n",
    "#                 interval = PercentileInterval(scale_num) ###\n",
    "#                 interval.get_limits(counts_image[time_i,strt:end,strt:end])\n",
    "#                 scale_array = interval(counts_image[time_i,strt:end,strt:end])\n",
    "#                 sliced_image = counts_image[0,strt:end,strt:end] \n",
    "#                 result = scale_array\n",
    "#                 if i_box < 3:\n",
    "#                     print('too small of an image to calculate\\n')\n",
    "#                 elif i_box >= 3:\n",
    "#                     x1, y1 = centroid_com(result)\n",
    "#                     centroid_com_arr_x.append(x1)\n",
    "#                     centroid_com_arr_y.append(y1)\n",
    "# #                     print(i_box,strt,end)\n",
    "# #                     print('Box Size: ', i_box,'x',i_box)\n",
    "# #                     print('COM: ',x1,y1)\n",
    "# #                     print('2dG: ',x2,y2)\n",
    "#                     if i_box == 15:\n",
    "#                         centroid_com_arr_x1.append(x1)\n",
    "#                         centroid_com_arr_y1.append(y1)\n",
    "#                         cen_com_arr_x.append(x1)\n",
    "#                         cen_com_arr_y.append(y1)\n",
    "#                     num = num+1\n",
    "# #                     print(num,time_i,'\\n')\n",
    "# #                     plt.imshow(result)\n",
    "# #                     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array1=[]\n",
    "# j=1\n",
    "# plt.figure(figsize=(15,10))\n",
    "# for i in range(len(centroid_com_arr_x)):\n",
    "#     test = centroid_com_arr_x[i] - centroid_2dG_arr_x[i]\n",
    "# #     print(test)\n",
    "#     array1.append(test)\n",
    "\n",
    "# # plt.plot(array1)\n",
    "# # plt.ylim([-0.2,.1])# x=400 # plt.xlim([x,x+15])# print(dict_cen[str_num_arr[0]][5])\n",
    "\n",
    "# # same_num=14\n",
    "# # print(array[same_num])\n",
    "# # # print(dict_cen['cen_com_arr_'+xy+'_'+str(nmb)][14],dict_cen['cen_2dg_arr_'+xy+'_'+str(nmb)][14])\n",
    "# # test = dict_cen['cen_com_arr_'+xy+'_'+str(nmb)][same_num]-dict_cen['cen_2dg_arr_'+xy+'_'+str(nmb)][same_num]\n",
    "# # print(test)\n",
    "\n",
    "# # # print(ex1,'\\n\\n',ex2)\n",
    "# # plt.title('CoM and 2dg difference for '+xy+' values at z='+str(nmb))\n",
    "# # plt.xlabel('2D Gaussian values (2dg)')\n",
    "# # plt.ylabel('Center of Mass values (CoM)')\n",
    "# # plt.plot(dg2,com1,'.')\n",
    "# # plt.show()\n",
    "# # plt.plot(centroid_com_arr_x,centroid_2dG_arr_x,'.') \n",
    "\n",
    "# # test = centroid_com_arr_x[i] - centroid_2dG_arr_x[i]\n",
    "# # plt.plot(test,'.')\n",
    "\n",
    "# # Note that the aperture photometry values no longer appear as negative numbers. In the beginning when I would adjust only the radius and its box size, I believe the box size I chose and the way I calculated the centroid is what caused the values to be off. \n",
    "\n",
    "# -------\n",
    "# # xy='y'\n",
    "# # nmb=0\n",
    "# # com=dict_cen['cen_com_arr_'+xy+'_'+str(nmb)]\n",
    "# # dg=dict_cen['cen_2dg_arr_'+xy+'_'+str(nmb)]\n",
    "# # array=[]\n",
    "# # i=0\n",
    "# # for i in range(len(com)):\n",
    "# #     test = com[i] - dg[i]\n",
    "# # #     print(test)\n",
    "# #     array.append(test)\n",
    "# #     plt.title('CoM and 2dg difference for '+xy+' values at z='+str(nmb))\n",
    "# # plt.plot(array)\n",
    "\n",
    "# def cen_boxsize_diff(xy,nmb):\n",
    "#     com=dict_cen['cen_com_arr_'+xy+'_'+str(nmb)]\n",
    "#     dg=dict_cen['cen_2dg_arr_'+xy+'_'+str(nmb)]\n",
    "#     array_com=[]\n",
    "#     array_dg = []\n",
    "#     for i in range(len(com)):\n",
    "# #         test = com[i] - dg[i]\n",
    "#         box_size=(3+2*i)\n",
    "#         subtr_com = com[i] -(3+2*i)/2 #subtracting box size over 2\n",
    "#         subtr_2dg = dg[i]-(3+2*i)/2\n",
    "#         abs_com = np.abs(subtr_com)\n",
    "#         abs_2dg = np.abs(subtr_2dg)\n",
    "#         array_com.append(abs_com)\n",
    "#         array_dg.append(abs_2dg)\n",
    "#         print('i = '+str(i))\n",
    "#         print(str(box_size)+'x'+str(box_size))\n",
    "#         print('abs of subtracting COM center:'+str(abs_com))\n",
    "#         print('abs of subtracting 2dG center:'+str(abs_2dg),'\\n')\n",
    "# #         plt.title('CoM and 2dg difference for '+xy+' values at z='+str(nmb))\n",
    "#     plt.plot(array_com,'.',label='com '+str(xy)+', z= '+str(nmb))\n",
    "#     plt.plot(array_dg,'.',label='2dg '+str(xy)+', z= '+str(nmb))\n",
    "\n",
    "\n",
    "# # plt.plot(com)\n",
    "# # print(com)\n",
    "# cen_boxsize_diff('x',2)\n",
    "# # test_2('y',0)\n",
    "# # c pickle \n",
    "\n",
    "# plt.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_ascii(dir_lightcurv,col_1,col_2,part_str):\n",
    "#     data = ascii.read(dir_lightcurv)\n",
    "#     ap_phot = data[col_1]\n",
    "#     bmjd = data[col_2]\n",
    "#     plt.plot(bmjd,ap_phot,'.',label=part_str)\n",
    "#plot_ascii(lightcurve_1,col_1,col_2,'Part 1')\n",
    "# plot_ascii(lightcurve_2,col_1,col_2,'Part 2')\n",
    "# plot_ascii(lightcurve_3,col_1,col_2,'Part 3')\n",
    "# plot_ascii(lightcurve_4,col_1,col_2,'Part 4')\n",
    "# plot_ascii(lightcurve_5,col_1,col_2,'Part 5')\n",
    "# plot_ascii(lightcurve_6_1,col_1,col_2,'Part 6-1')\n",
    "# plot_ascii(lightcurve_6_2,col_1,col_2,'Part 6-2')\n",
    "# plot_ascii(lightcurve_7,col_1,col_2,'Part 7')\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# def plot_ascii(dir_lightcurv,col_1,col_2,part_str):\n",
    "#     data = ascii.read(dir_lightcurv)\n",
    "#     ap_phot = data[col_1]\n",
    "#     bmjd = data[col_2]\n",
    "#     ap_phot = median_flux(ap_phot)\n",
    "#     plt.plot(bmjd,ap_phot,'.',label=part_str)\n",
    "# plot_ascii(lightcurve_1,col_1,col_2,'Part 1')\n",
    "#     print(ap_phot)\n",
    "#     return ap_phot,bmjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# july302019\n",
    "# # ### First attempt\n",
    "# maxorder=2 #max order of the polynomial\n",
    "# #---------------------------\n",
    "# n_ipsv=1\n",
    "# for i in range(maxorder):\n",
    "#     n_ipsv=n_ipsv +(i+2)\n",
    "# #     print(i,maxorder)\n",
    "# print('Parameters for maxorder of ',maxorder,' is ',n_ipsv) #Gives us the parameters depending the maxorder\n",
    "# guess_ipsv = np.ones(n_ipsv);# c0_guess=1;# guess_ipsv[0] = c0_guess\n",
    "# print(guess_ipsv)\n",
    "   \n",
    "# def choose_ipsv(maxorder):\n",
    "#     def f_ipsv(xy_arr,*p):\n",
    "#         index = 1\n",
    "#         ipsv = p[0]\n",
    "#         for i in range(maxorder):\n",
    "#             order=i+1\n",
    "#             loop_order=i+2\n",
    "#             for j in range(loop_order):\n",
    "#                 ipsv=ipsv+p[index]*x**(order-j)*y**(j)\n",
    "#                 index=index+1\n",
    "#     return(f_ipsv)\n",
    "\n",
    "# def IPSV_Model(cen_arr,c0,c1,c2,c3,c4,c5):\n",
    "#     x=cen_arr[0,:]\n",
    "#     y=cen_arr[1,:]\n",
    "#     x_bar=np.mean(cen_arr[0,:])\n",
    "#     y_bar=np.mean(cen_arr[1,:])\n",
    "#     ipsv_model = c0+c1*(x-x_bar)+c2*(y-y_bar)+c3*(x-x_bar)**2+c4*(y-y_bar)**2+c5*(x-x_bar)*(y-y_bar)\n",
    "#     return ipsv_model\n",
    "####___________________\n",
    "\n",
    "# def ipsv_fourier_mTerms(xyt_arr,c0,c1,c2,c3,c4,c5,a0,a1,b1,a2,b2,a3,b3,a4, b4, a5, b5, a6, b6, a7, b7,freq,offset):\n",
    "#     x=xyt_arr[0,:]\n",
    "#     y=xyt_arr[1,:]\n",
    "#     t=xyt_arr[2,:]\n",
    "    \n",
    "#     x_bar=np.mean(x)\n",
    "#     y_bar=np.mean(y)\n",
    "    \n",
    "#     ipsv_m = c0+c1*(x-x_bar)+c2*(y-y_bar)+c3*(x-x_bar)**2+c4*(y-y_bar)**2+c5*(x-x_bar)*(y-y_bar)\n",
    "    \n",
    "#     fourier_m = a0*np.sin(2.*0*np.pi*freq*t)\\\n",
    "#             + a1*np.sin(2.*1*np.pi*freq*t)\\\n",
    "#             + b1*np.cos(2.*1*np.pi*freq*t)\\\n",
    "#             + a2*np.sin(2.*2*np.pi*freq*t)\\\n",
    "#             + b2*np.cos(2.*2*np.pi*freq*t)\\\n",
    "#             + a3*np.sin(2.*3*np.pi*freq*t)\\\n",
    "#             + b3*np.cos(2.*3*np.pi*freq*t)\\\n",
    "#             + a4*np.sin(2.*4*np.pi*freq*t)\\\n",
    "#             + b4*np.cos(2.*4*np.pi*freq*t)\\\n",
    "#             + a5*np.sin(2.*5*np.pi*freq*t)\\\n",
    "#             + b5*np.cos(2.*5*np.pi*freq*t)\\\n",
    "#             + a6*np.sin(2.*6*np.pi*freq*t)\\\n",
    "#             + b6*np.cos(2.*6*np.pi*freq*t)\\\n",
    "#             + a7*np.sin(2.*7*np.pi*freq*t)\\\n",
    "#             + b7*np.cos(2.*7*np.pi*freq*t)\\\n",
    "#             + offset\n",
    "#     model = ipsv_m * fourier_m\n",
    "#     return model\n",
    "\n",
    "\n",
    "# ipsv_gp = [1,1,1,1,1,1]\n",
    "# f_gp = [1,.05,.05,.05,.05,.05,.05,.05,.05,.05,.05,.05,.05,.05,.05,1/(5/24),0]\n",
    "# gp=[];gp.extend(ipsv_gp);gp.extend(f_gp)\n",
    "\n",
    "# params_mTerms, pcov = curve_fit(ipsv_fourier_mTerms,xyt_arr,c_f1,p0=gp) \n",
    "\n",
    "# flux_div_fullModel_7 = c_f1 / (ipsv_fourier_mTerms(xyt_arr,*params_mTerms))\n",
    "# resid_mTerms = c_f1 - (ipsv_fourier_mTerms(xyt_arr,*params_mTerms))\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "\n",
    "# plt.plot(c_h1,flux_div_fullModel,'.')\n",
    "\n",
    "# plt.plot(c_h1,flux_div_fullModel_7,'.')\n",
    "\n",
    "# plt.plot(resid_mTerms,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# july 31 2019\n",
    "\n",
    "# n_ipsv=1\n",
    "# # Parameters of functions for ipsv and fourier\n",
    "# for i in range(maxorder):\n",
    "#     n_ipsv=n_ipsv +(i+2)\n",
    "# guess_ipsv = np.zeros(n_ipsv) \n",
    "# print('Max order: ',n_ipsv) # ipsv parameters\n",
    "# nparams = 2+2*(nmodes)\n",
    "# print('Modes: ',nparams)# fourier parameters\n",
    "\n",
    "# # adding specific guess parameters for fourier \n",
    "# guess_fourier = np.zeros(nparams)\n",
    "\n",
    "# period_guess=5/24\n",
    "# offset_guess=1\n",
    "# guess_fourier[0] = period_guess\n",
    "# guess_fourier[1] = offset_guess\n",
    "\n",
    "# combining the two guess parameters together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aug2\n",
    "\n",
    "# test4 = c_f1/(ipsv_fourier_m(xyt_arr,*gp))\n",
    "\n",
    "# ori_bin_flux =bin_funct(c_f1,5)\n",
    "# testplt =bin_funct(test4,10)\n",
    "# # plt.title('original /w bin')\n",
    "# # plt.plot(ori_bin_flux,'.')\n",
    "# # plt.show()\n",
    "\n",
    "# plt.title('original /w bin and ipsv/fourier')\n",
    "# plt.plot(testplt)\n",
    "\n",
    "# #-----\n",
    "# test = c_f1 /(IPSV_Model(cen_arr,*params_ipsv))\n",
    "# plt.plot(test,'.')\n",
    "# plt.show()\n",
    "# test2 =bin_funct(c_f1,11)\n",
    "# fl_w_ipsv =bin_funct(test,11)\n",
    "\n",
    "# print('all clipped')\n",
    "# plt.title('original')\n",
    "# plt.plot(c_h1,c_f1,'.',label='clipped')\n",
    "# plt.show()\n",
    "# plt.title('original /w bin')\n",
    "# plt.plot(test2,'.')\n",
    "# plt.show()\n",
    "# plt.title('original w/ bin and ipsv model')\n",
    "# plt.plot(fl_w_ipsv,'.')\n",
    "\n",
    "# plt.show()\n",
    "# plt.plot(c_f1,'.',label='clipped')\n",
    "# plt.plot(IPSV_Model(cen_arr,*params_ipsv),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug3\n",
    "# fourier_params, covar = curve_fit(choose_fourier(nmodes),c_h1,c_f1,p0=guess_fourier)\n",
    "# p_ipsv, covar = curve_fit(choose_ipsv(maxorder),cen_arr,c_f1,p0=guess_ipsv)\n",
    "# full_params, covar = curve_fit(choose_f_ipsv(nmodes,maxorder),xyt_arr,c_f1,p0=guess_ipsv_f)\n",
    "\n",
    "\n",
    "\n",
    "# # getting the same parameters from the full model set\n",
    "# # this is to divide out the ipsv of the full model.\n",
    "# params_ipsv = full_params[0:n_ipsv]\n",
    "# params_f = full_params[n_ipsv::]\n",
    "\n",
    "\n",
    "# model_ipsv = choose_ipsv(maxorder)(cen_arr,*params_ipsv)\n",
    "# model_fourier = choose_fourier(nmodes)(c_h1,*params_f)\n",
    "\n",
    "\n",
    "# # ipsv is divided out of the dull model only leaving the fourier model\n",
    "# only_fourier_model = model_final/model_ipsv\n",
    "\n",
    "\n",
    "# #### created from the definition that only uses the fourier model\n",
    "# # plt.figure(figsize=(15,10))\n",
    "# plt.plot(model_fourier,'-',label='fourier')\n",
    "# # plt.plot(model_ipsv,'.',label='ipsv')\n",
    "# # plt.plot(model_final,'.',label='Full model')\n",
    "# plt.plot(only_fourier_model,'-',label = 'full model w/ ipsv divided out')\n",
    "# # plt.legend(loc='upper right')\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# # plt.figure(figsize=(15,10))\n",
    "# # data_div_ipsv = c_f1 / model_ipsv\n",
    "# # plt.plot(data_div_ipsv,'.',label = 'flux divided by ipsv')\n",
    "# # plt.plot(only_fourier_model,label='fourier')\n",
    "# # plt.legend(loc='upper right')\n",
    "# --------------------------------------------------------------\n",
    "# # Checks if the models are correct with their parameters\n",
    "# m_full= model_f*model_ipsv\n",
    "# checker = m_full/model_final\n",
    "# print(np.mean(checker))\n",
    "\n",
    "\n",
    "# ##Example\n",
    "# test_arr = [1,2,3,4,5]\n",
    "# shift_test = np.roll(test_arr,1)\n",
    "# # print(shift_test)\n",
    "\n",
    "\n",
    "# c_f =clip_of_mask(data_arr[0],data_arr[0]) \n",
    "# c_h = clip_of_mask(data_arr[0],data_arr[1])\n",
    "# c_cenx = clip_of_mask(data_arr[0],data_arr[2])\n",
    "# c_ceny = clip_of_mask(data_arr[0],data_arr[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug7 2019\n",
    "\n",
    "# import pickle\n",
    "# SAMPLE:-------------------------------------------\n",
    "# with open(filename, wb) as f:\n",
    "#     pickle.dump(your_content, f)\n",
    "# with open(filename, rb) as f:\n",
    "#     var_you_want_to_load_into = pickle.load(f)\n",
    "# --------------------------------------------------\n",
    "\n",
    "# name = 'CEN_com_7x7_prt'+str(part_num)+'r4.pickle'\n",
    "# name_2 = 'CEN_2DG_7x7.pickle'\n",
    "\n",
    "# with open(name, 'wb') as f:\n",
    "#     pickle.dump([phot_ap_arr,time_arr,cen_com_arr_x,cen_com_arr_y], f)\n",
    "\n",
    "# with open(name,'rb') as f:\n",
    "#     sam = pickle.load(f)\n",
    "# sam[0]\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.ylim([.97,1.04])\n",
    "# # plt.plot(sam[1],median_flux(sam[0]),'.')\n",
    "# plot_ascii(lightcurve_1,col_1,col_2,'Part ...')\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# for z in range(int(len(counts_image))-1):\n",
    "#     for x in range(int(len(counts_image)/2)):\n",
    "#         for y in range(int(len(counts_image)/2)):\n",
    "#             isitnan = math.isnan(counts_image[z,x,y])\n",
    "#             print(isitnan)\n",
    "#             if isitnan == True:\n",
    "#     #             print('left pixel: ',result[x,y-1])#correct\n",
    "#     #             print('right pixel: ',result[x,y+1])#correct\n",
    "#     #             print('lower pixel:',result[x+1,y])#correct\n",
    "#     #             print('upper pixel:',result[x-1,y])#correct\n",
    "#                 leftc=counts_image[z,x,y-1]\n",
    "#                 rightc=counts_image[z,x,y+1]\n",
    "#                 bottomc=counts_image[z,x+1,y]\n",
    "#                 upperc=counts_image[z,x-1,y]\n",
    "#                 mean_of_c = np.nanmean([leftc,rightc,bottomc,upperc])\n",
    "#                 counts_image[z,x,y] = mean_of_c\n",
    "\n",
    "# centroid_2dG_arr_x[cen_i]\n",
    "# print(result[0,-1,2])##x,y or row,col\n",
    "# print(result)\n",
    "# for x in range(len(result)):\n",
    "#     for y in range(len(result)):\n",
    "#         isitnan = math.isnan(result[x,y])\n",
    "#         if isitnan == True:\n",
    "# #             print('left pixel: ',result[x,y-1])#correct\n",
    "# #             print('right pixel: ',result[x,y+1])#correct\n",
    "# #             print('lower pixel:',result[x+1,y])#correct\n",
    "# #             print('upper pixel:',result[x-1,y])#correct\n",
    "#             leftc=result[x,y-1]\n",
    "#             rightc=result[x,y+1]\n",
    "#             bottomc=result[x+1,y]\n",
    "#             upperc=result[x-1,y]\n",
    "#             mean_of_c = np.nanmean([leftc,rightc,bottomc,upperc])\n",
    "#             result[x,y] = mean_of_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # aug7 2019\n",
    "# # ----------------------------------------------------------------------------------------------------#\n",
    "# def IPSV_Model(cen_arr,c0,c1,c2,c3,c4,c5):\n",
    "#     x=cen_arr[0,:]\n",
    "#     y=cen_arr[1,:]\n",
    "#     x_bar=np.mean(cen_arr[0,:])\n",
    "#     y_bar=np.mean(cen_arr[1,:])\n",
    "#     ipsv_model = c0+c1*(x-x_bar)+c2*(y-y_bar)+c3*(x-x_bar)**2+c4*(y-y_bar)**2+c5*(x-x_bar)*(y-y_bar)\n",
    "#     return ipsv_model\n",
    "    \n",
    "# # These only focuses one mode at\n",
    "# def fourier_sinusoidal_series_twoModes(x,a0,a1,b1,a2,b2,freq,offset):\n",
    "#     fourier_model = a0*np.cos(2.*0*np.pi*freq*x) \\\n",
    "#              + a1*np.cos(2.*1*np.pi*freq*x) \\\n",
    "#              + b1*np.sin(2.*1*np.pi*freq*x) \\\n",
    "#              + a2*np.cos(2.*2*np.pi*freq*x) \\\n",
    "#              + b2*np.sin(2.*2*np.pi*freq*x) \\\n",
    "#              + offset\n",
    "#     return fourier_model\n",
    "\n",
    "\n",
    "# def ipsv_fourier_m(xyt_arr,c0,c1,c2,c3,c4,c5,a0,a1,b1,a2,b2,freq,offset):\n",
    "#     x=xyt_arr[0,:]\n",
    "#     y=xyt_arr[1,:]\n",
    "#     t=xyt_arr[2,:]\n",
    "    \n",
    "#     x_bar=np.mean(x)\n",
    "#     y_bar=np.mean(y)\n",
    "    \n",
    "#     ipsv_m = c0+c1*(x-x_bar)+c2*(y-y_bar)+c3*(x-x_bar)**2+c4*(y-y_bar)**2+c5*(x-x_bar)*(y-y_bar)\n",
    "    \n",
    "#     fourier_m = a0*np.cos(2.*0*np.pi*freq*t) \\\n",
    "#              + a1*np.cos(2.*1*np.pi*freq*t) \\\n",
    "#              + b1*np.sin(2.*1*np.pi*freq*t) \\\n",
    "#              + a2*np.cos(2.*2*np.pi*freq*t) \\\n",
    "#              + b2*np.sin(2.*2*np.pi*freq*t) \\\n",
    "#              + offset\n",
    "#     model = ipsv_m * fourier_m\n",
    "#     return model\n",
    "\n",
    "# # --- curve fitting using a IPSV model only\n",
    "# c_f1 =clip_of_mask(ap_ph_1,ap_ph_1)\n",
    "# c_h1 = clip_of_mask(ap_ph_1,bmjd_1)\n",
    "# c_cenx = clip_of_mask(ap_ph_1,x_cen1)\n",
    "# c_ceny = clip_of_mask(ap_ph_1,y_cen1)\n",
    "\n",
    "# cen_arr=np.array([c_cenx,c_ceny]) ##creates a 2 col array\n",
    "# # # # so then 'cen_arr[col,row]' 1st Column: x_cen. 2nd Column: y_cen\n",
    "\n",
    "# ipsv_gp = [0,0,0,0,0,0]\n",
    "# params_ipsv, pcov = curve_fit(IPSV_Model,cen_arr,c_f1,p0=ipsv_gp) ##works\n",
    "\n",
    "# # # plt.figure(figsize=(15,10))\n",
    "# # plt.title('IPSV model and Light Curve (CH1 Part 1)')\n",
    "# # plt.plot(c_h1,c_f1,'.',label='light curve')\n",
    "# # plt.plot(c_h1,IPSV_Model(cen_arr,*params_ipsv),'.',label='IPSV model')\n",
    "# # plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "# # --- Using model with Fourier series\n",
    "# c_f1 = clip_of_mask(ap_ph_1,ap_ph_1) ##Clipped flux data \n",
    "# c_h1 = clip_of_mask(ap_ph_1,bmjd_1)  ##Clipped time data\n",
    "\n",
    "# ## Guess Parameters.\n",
    "# f_gp = [1,.05,.05,.05,.05,1/(5/24),1]\n",
    "\n",
    "# ## Adding the function into the curve fit.\n",
    "# params_f, pcov = curve_fit(fourier_sinusoidal_series_twoModes,c_h1,c_f1,p0=f_gp)\n",
    "\n",
    "# # # plt.figure(figsize=(15,10))\n",
    "# # plt.title('Astrophysical model and Light Curve (CH1 Part 1)')\n",
    "# # plt.plot(c_h1,c_f1,'.',label='Light Curve')\n",
    "# # plt.plot(c_h1,fourier_sinusoidal_series_twoModes(c_h1,*params_f),label='Astrophys. Model',linewidth=3)\n",
    "# # plt.legend(loc='upper right')\n",
    "\n",
    "# # test = c_f1 /(fourier_sinusoidal_series_twoModes(c_h1,*params_f)*IPSV_Model(cen_arr,*params_ipsv))\n",
    "# # plt.plot(c_h1,test,'.')\n",
    "\n",
    "# # --- Using model with both Fourier and IPSV models\n",
    "# c_f1 =clip_of_mask(ap_ph_1,ap_ph_1)\n",
    "# c_h1 = clip_of_mask(ap_ph_1,bmjd_1)\n",
    "# c_cenx = clip_of_mask(ap_ph_1,x_cen1)\n",
    "# c_ceny = clip_of_mask(ap_ph_1,y_cen1)\n",
    "\n",
    "# xyt_arr=np.array([c_cenx,c_ceny,c_h1])\n",
    "\n",
    "# ipsv_gp = [0,0,0,0,0,0]\n",
    "# f_gp = [1,.05,.05,.05,.05,1/(5/24),0]\n",
    "# gp=[];gp.extend(ipsv_gp);gp.extend(f_gp)\n",
    "# # print(len(gp))\n",
    "# params_all, pcov = curve_fit(ipsv_fourier_m,xyt_arr,c_f1,p0=gp) \n",
    "\n",
    "# ipsv_mp = params_all[0:6]\n",
    "# f_mp = params_all[6:13]\n",
    "\n",
    "# # plt.figure(figsize=(15,10))\n",
    "# # plt.title('IPSV/Astrophys. model and Light Curve (CH1 Part 1)')\n",
    "# # plt.plot(c_h1,c_f1,'.',label='Light Curve')\n",
    "# # plt.plot(c_h1,ipsv_fourier_m(xyt_arr,*params_all),'.',label='IPSV/Astrophys. Model')\n",
    "# # plt.legend(loc='upper right')\n",
    "# # test = ipsv_fourier_m(xyt_arr,*params_all)/fourier_sinusoidal_series_twoModes(c_h1,*params_f)\n",
    "# # plt.plot(test-IPSV_Model(cen_arr,*ipsv_mp))\n",
    "\n",
    "# c_f1 =clip_of_mask(ap_ph_1,ap_ph_1)\n",
    "# c_h1 = clip_of_mask(ap_ph_1,bmjd_1)\n",
    "# c_cenx = clip_of_mask(ap_ph_1,x_cen1)\n",
    "# c_ceny = clip_of_mask(ap_ph_1,y_cen1)\n",
    "\n",
    "# cen_arr=np.array([c_cenx,c_ceny]) ##creates a 2 col array\n",
    "# # # # so then 'cen_arr[col,row]' 1st Column: x_cen. 2nd Column: y_cen\n",
    "\n",
    "# params_ipsv, pcov = curve_fit(IPSV_Model,cen_arr,c_f1,p0=ipsv_mp) \n",
    "# # test_ipsv = c_f1 /(IPSV_Model(cen_arr,*params_ipsv))\n",
    "# # plt.plot(test_ipsv,'.')\n",
    "# # plt.show()\n",
    "\n",
    "# params_f, pcov = curve_fit(fourier_sinusoidal_series_twoModes,c_h1,c_f1,p0=f_mp) \n",
    "# # test_f = c_f1 / (fourier_sinusoidal_series_twoModes(c_h1,*params_f))\n",
    "# # plt.plot(test_f,'.')\n",
    "# # plt.show()\n",
    "\n",
    "# ## Guess parameters\n",
    "# ipsv_gp = [0,0,0,0,0,0]\n",
    "# f_gp = [1,.05,.05,.05,.05,1/(5/24),0]\n",
    "# gp=[];gp.extend(ipsv_gp);gp.extend(f_gp)\n",
    "\n",
    "# ## Calculates the measured parameters using the curve fit and def function.\n",
    "# ##------------------------------------------------------------------\n",
    "# params_f, pcov = curve_fit(fourier_sinusoidal_series_twoModes,c_h1,c_f1,p0=f_gp)\n",
    "# params_ipsv, pcov = curve_fit(IPSV_Model,cen_arr,c_f1,p0=ipsv_gp)\n",
    "# params_all, pcov = curve_fit(ipsv_fourier_m,xyt_arr,c_f1,p0=gp) \n",
    "\n",
    "# # ipsv_mp = params_all[0:6]\n",
    "# # f_mp = params_all[6:13]\n",
    "\n",
    "# # ip =IPSV_Model(cen_arr,*ipsv_mp)\n",
    "# # f=fourier_sinusoidal_series_twoModes(c_h1,*f_mp)\n",
    "# # mm =ipsv_fourier_m(xyt_arr,*params_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %matplotlib nbagg\n",
    "# # fig,ax = plt.subplots()    \n",
    "\n",
    "# # # myax = ax.imshow(test[0,:,:])\n",
    "# # myax = ax.imshow(test[0,0,0],color='red')\n",
    "# # ax.set_title('hover over the image')\n",
    "# # datacursor(myax)\n",
    "# plt.show()\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# max_value = 5\n",
    "# min_value = -max_value # for instance\n",
    "\n",
    "# plt.imshow(test[0,:,:], interpolation='nearest',\n",
    "#            vmin=min_value, vmax=max_value)\n",
    "# plt.show()\n",
    "\n",
    "# def replace_nan(counts_image):\n",
    "#     for z in range(int(len(counts_image))):\n",
    "#         for x in range(int(len(counts_image)/2)):\n",
    "#             for y in range(int(len(counts_image)/2)):\n",
    "#     #             print('  z:',z,'  x:',x,'  y:',y)\n",
    "#     #             print(counts_image[z,x,y])\n",
    "#                 isitnan = math.isnan(counts_image[z,x,y])\n",
    "#                 if isitnan == True:\n",
    "#     #                 print('T')\n",
    "#     #                 print(z,x,y)\n",
    "#                     addy = y+1\n",
    "#                     miny=y-1\n",
    "#                     if addy>=31:\n",
    "#                         addy=y\n",
    "#     #                 print('center pixel:',counts_image[z,x,y])\n",
    "#     #                 print('left pixel: ',counts_image[z,x,y-1])#correct\n",
    "#     #                 print('right pixel: ',counts_image[z,x,addy])#correct\n",
    "#     #                 print('lower pixel:',counts_image[z,x+1,y])#correct\n",
    "#     #                 print('upper pixel:',counts_image[z,x-1,y])#correct\n",
    "\n",
    "#                     leftc=counts_image[z,x,y-1]\n",
    "#                     rightc=counts_image[z,x,addy]\n",
    "#                     bottomc=counts_image[z,x+1,y]\n",
    "#                     upperc=counts_image[z,x-1,y]\n",
    "#                     mean_of_c = np.nanmean([leftc,rightc,bottomc,upperc])\n",
    "#                     counts_image[z,x,y] = mean_of_c\n",
    "#     return(counts_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aug12\n",
    "# def replace_nan(im):\n",
    "#     new_im = im[:,:,:]\n",
    "#     for z in range(int(len(im))):\n",
    "#         for x in range(int(len(im)/2)):\n",
    "#             for y in range(int(len(im)/2)):\n",
    "#     #             print('  z:',z,'  x:',x,'  y:',y)\n",
    "#     #             print(counts_image[z,x,y])\n",
    "#                 isitnan = math.isnan(im[z,x,y])\n",
    "#     #             print(z,x,y)\n",
    "#                 if isitnan == True:\n",
    "#     #                 print('T')\n",
    "# #                     print(z,x,y)\n",
    "#                     print(z+1,'(',str(y+1),',',str(x+1),')')\n",
    "#                     addy = y+1\n",
    "#                     miny=y-1\n",
    "#                     addx=x+1\n",
    "#                     minx=x-1\n",
    "#                     if addy>31:\n",
    "#                         addy=y\n",
    "#                     if miny<0:\n",
    "#                         miny=y\n",
    "#                     if addx>31:\n",
    "#                         addx=x\n",
    "#                     if minx<0:\n",
    "#                         minx=x\n",
    "# #                     print('center pixel:',im[z,x,y])\n",
    "#                     print('left pixel: ',im[z,x,miny])#correct\n",
    "#                     print('right pixel: ',im[z,x,addy])#correct\n",
    "#                     print('lower pixel:',im[z,addx,y])#correct\n",
    "#                     print('upper pixel:',im[z,minx,y])#correct\n",
    "#                     leftc=im[z,x,miny]\n",
    "#                     rightc=im[z,x,addy]\n",
    "#                     bottomc=im[z,addx,y]\n",
    "#                     upperc=im[z,minx,y]\n",
    "#                     mean_of_c = np.nanmean([leftc,rightc,bottomc,upperc])\n",
    "#                     new_im[z,x,y] = mean_of_c\n",
    "# #                     print(im[z,x,y])\n",
    "# #                     print(mean_of_c)\n",
    "# #                    \n",
    "#     return(im)\n",
    "\n",
    "# # len(test)\n",
    "# # addy = y+1\n",
    "# # miny=y-1\n",
    "# # addx=x+1\n",
    "# # minx=x-1\n",
    "# # if addy>31:\n",
    "# #     addy=y\n",
    "# # if miny<0:\n",
    "# #     miny=y\n",
    "# # if addx>31:\n",
    "# #     addx=x\n",
    "# # if minx<0:\n",
    "# #     minx=x\n",
    "# # leftc=im[z,x,miny]\n",
    "# # rightc=im[z,x,addy]\n",
    "# # bottomc=im[z,addx,y]\n",
    "# # upperc=im[z,minx,y]\n",
    "# # # print('center pixel:',im[z,x,y])\n",
    "# # print('left pixel: ',leftc)#correct\n",
    "# # print('right pixel: ',rightc)#correct\n",
    "# # print('lower pixel:',bottomc)#correct\n",
    "# # print('upper pixel:',upperc)#correct\n",
    "# # mean_of_c = np.nanmean([leftc,rightc,bottomc,upperc])\n",
    "# # test[z,x,y] = mean_of_c\n",
    "# # plt.imshow(test[n,:,:]);plt.show()\n",
    "# # plt.imshow(im[n,:,:]);plt.show()\n",
    "\n",
    "# testt = replace_nan(im)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# im =image_data[:,:,:]\n",
    "# newimag = replace_nanPixels(im)\n",
    "# plt.imshow(newimag[1,:,:])\n",
    "# z = 1;x=1;y=3\n",
    "# print(z+1,'(',str(y+1),',',str(x+1),')')\n",
    "# print(newimag[z,x,y])\n",
    "\n",
    "# newimag=newimag*conversion_factor\n",
    "# plt.imshow(newimag[0,:,:])\n",
    "\n",
    "# print(newimag[0,0,1])\n",
    "# print(counts_image[0,0,2])\n",
    "\n",
    "# ---------------------------------------------\n",
    "#                     if addy>31:# avoid the error from corners\n",
    "#                         rightCen=float('NaN')  \n",
    "#                     else:\n",
    "#                         rightCen=dataIm[z,x,addy]\n",
    "#     #               ------------------------\n",
    "#                     if miny<0:\n",
    "#                         leftCen=float('NaN') \n",
    "#                     else:\n",
    "#                         leftCen=dataIm[z,x,miny]\n",
    "#     #               ------------------------\n",
    "#                     if minx<0:\n",
    "#                         upCen=float('NaN')\n",
    "#                     else:\n",
    "#                         upCen=dataIm[z,minx,y]\n",
    "#     #               ------------------------\n",
    "#                     if addx>31: \n",
    "#                         downCen=float('NaN')\n",
    "#                     else:\n",
    "#                         downCen=dataIm[z,addx,y]  \n",
    "#     #               ------------------------\n",
    "#     #               ------------------------\n",
    "#                     if minx<0:\n",
    "#                         upLeft = float('NaN')\n",
    "#                     else:\n",
    "#                         upLeft = dataIm[z,minx,miny]\n",
    "#     #               ------------------------\n",
    "#                     if minx<0:\n",
    "#                         upRight = float('NaN')\n",
    "#                     else:\n",
    "#                         upRight = dataIm[z,minx,addy]\n",
    "#     #               ------------------------\n",
    "#                     if addx>31:\n",
    "#                         downLeft = float('NaN')\n",
    "#                     else:\n",
    "#                         downLeft = dataIm[z,addx,miny]\n",
    "#     #               ------------------------                                \n",
    "#                     if addy>31:\n",
    "#                         downRight = float('NaN')\n",
    "#                     else:\n",
    "#                         downRight = dataIm[z,addx,addy]\n",
    "    #               ------------------------    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug 13\n",
    "\n",
    "# # Handles bad pixels\n",
    "# data = counts_image[0,:,:]\n",
    "# aperture = CircularAperture(positions,r=7.)\n",
    "# mask = np.zeros_like(data,dtype=bool)\n",
    "# n=15\n",
    "# data[n,n]=100\n",
    "# mask[n,n]=True\n",
    "# plt.imshow(data)\n",
    "# t1 = aperture_photometry(data, aperture, mask=mask)\n",
    "# t1['aperture_sum'].info.format = '%.8g'  # for consistent table output\n",
    "# print(t1['aperture_sum'])\n",
    "\n",
    "# t2 = aperture_photometry(data, aperture)\n",
    "# t2['aperture_sum'].info.format = '%.8g'  # for consistent table output\n",
    "# print(t2['aperture_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         for l in range(0,64):\n",
    "#             cenx = dict_cen[str_num_arr[h_com]][index_box]\n",
    "#             ceny = dict_cen[str_num_arr[h_com+1]][index_box]\n",
    "#             positions = [(cenx, ceny)]\n",
    "#             apertures = CircularAperture(positions, r=r_1)\n",
    "#             annulus_apertures = CircularAnnulus(positions, r_in=r_2, r_out=r_3)\n",
    "#             apers = [apertures, annulus_apertures]\n",
    "#             phot_table = aperture_photometry(counts_image[l,:,:], apers)\n",
    "#             # print(phot_table)\n",
    "#             bkg_mean = phot_table['aperture_sum_1'] / annulus_apertures.area()\n",
    "#             bkg_sum = bkg_mean * apertures.area()\n",
    "#             final_sum = phot_table['aperture_sum_0'] - bkg_sum\n",
    "#             phot_table['residual_aperture_sum'] = final_sum\n",
    "#             # phot_table['residual_aperture_sum'].info.format = '%.8g'  # for consistent table output\n",
    "# #             print(phot_table['residual_aperture_sum']) \n",
    "#             ind_photometry_arr.append(final_sum)\n",
    "#             phot_ap_arr.append(final_sum)\n",
    "#             h_com = h_com+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radii=[7,11,14]\n",
    "# cen_i = 7\n",
    "# cenx = centroid_2dG_arr_x[cen_i]\n",
    "# ceny = centroid_2dG_arr_y[cen_i]\n",
    "# # print(cenx,ceny)\n",
    "# positions = [(cenx, ceny)]\n",
    "# apertures = [CircularAperture(positions,r=r) for r in radii]\n",
    "# phot_table = aperture_photometry(counts_image[t,:,:], apertures)\n",
    "# for col in phot_table.colnames:\n",
    "#     phot_table[col].info.format = '%.8g'  # for consistent table output\n",
    "# print(phot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only focus on COM centroid for aperture photometry\n",
    "# for filename in os.listdir(tot_dir_bcd[part_num-1]):\n",
    "#     if filename.endswith(\".fits\"): \n",
    "# #         dir_bcd ='/Users/melaniapena/Rsrch/Luhman_16_Research/bcd_files/only_bcd_part_1/SPITZER_I1_50037760_0000_0000_2_bcd.fits'\n",
    "#         dir_bcd = os.path.join(tot_dir_bcd[part_num-1],filename)\n",
    "#         fits_file = fits.open(dir_bcd)\n",
    "#         fits_data = get_pkg_data_filename(dir_bcd)\n",
    "#         list_Primary = fits_file[0]\n",
    "#         image_data= fits.getdata(fits_data, ext=0)\n",
    "        \n",
    "#         frame_t = fits_file[0].header['FRAMTIME']\n",
    "#         bmjd_obs = fits_file[0].header['BMJD_OBS']\n",
    "# #         print('bmjd observation:', bmjd_obs)\n",
    "#         flux_conv= fits_file[0].header['FLUXCONV']\n",
    "# #         print('Flux Conversion',flux_conv)\n",
    "#         gain = fits_file[0].header['GAIN']\n",
    "# #         print('Gain',gain)\n",
    "#         exp_time= fits_file[0].header['EXPTIME']\n",
    "# #         print('Exp-time', exp_time)\n",
    "#         conversion_factor = gain*exp_time/flux_conv\n",
    "# #         print(conversion_factor,'\\n')\n",
    "\n",
    "#         if part_num==2 or part_num==4 or part_num==5:###\n",
    "#             image_data=replace_nanPixels(image_data)###\n",
    "            \n",
    "#         counts_image = image_data * conversion_factor\n",
    "        \n",
    "#         num = 0\n",
    "#         centroid_com_arr_x = []\n",
    "#         centroid_com_arr_y = []\n",
    "        \n",
    "# #         print('delta x/y:'+str((npix-i_box)/2))\n",
    "# #         print('Box Size: ', i_box,'x',i_box)\n",
    "#         strt, end = slicing_im(npix,i_box)\n",
    "#         for time_i in range(0,64): \n",
    "#             interval = PercentileInterval(scale_num)\n",
    "#             interval.get_limits(counts_image[time_i,strt:end,strt:end])\n",
    "#             scale_array = interval(counts_image[time_i,strt:end,strt:end])\n",
    "# #             sliced_image = counts_image[0,strt:end,strt:end] \n",
    "# #             print(scale_array)\n",
    "#             result = scale_array\n",
    "#             if i_box == i_box:\n",
    "#                 x, y = centroid_com(result)\n",
    "#                 delta = (npix-i_box)/2 -.5\n",
    "#                 xc = x +delta\n",
    "#                 yc = y+delta\n",
    "        \n",
    "# #                 print(i_box,strt,end)\n",
    "# #                 print('COM: ',x,y)\n",
    "# #                 print('     ',xc,yc)\n",
    "#                 centroid_com_arr_x.append(xc)\n",
    "#                 centroid_com_arr_y.append(yc)\n",
    "#                 cen_com_arr_x.append(xc)\n",
    "#                 cen_com_arr_y.append(yc)\n",
    "#                 num = num+1\n",
    "# #                 print(num,time_i,'\\n')\n",
    "# #                 plt.imshow(result)\n",
    "# #                 plt.show()        \n",
    "\n",
    "# #       the empty array and dictionary will help organize the list of centroids thats\n",
    "# #       taken out of each file.\n",
    "#         str_num_arr=[]      \n",
    "#         dict_cen = {}\n",
    "# #         The line below is a define function (found in previous cell)\n",
    "# #         that organizes the centroids.\n",
    "#         org_dict(dict_cen,str_num_arr,centroid_com_arr_x,centroid_com_arr_y) \n",
    "# #         -----------------------------------------------\n",
    "# #         Aperture Photometry\n",
    "\n",
    "# #         focuses on the indiviual array of the photo data.\n",
    "#         ind_photometry_arr =[]\n",
    "#         h_com = 0 ##starting index for 2dG\n",
    "#         index_box = 0 ##measuring the box size ex 3x3....31x31. this is set in index tho\n",
    "#                        #index for 7x7 is now only zero\n",
    "#         for l in range(0,64):\n",
    "#             aperture_1 = aperture_sum(r_1,counts_image[l,:,:], dict_cen[str_num_arr[h_com]][index_box], dict_cen[str_num_arr[h_com+1]][index_box]) \n",
    "#             aperture_2 = aperture_sum(r_2,counts_image[l,:,:], dict_cen[str_num_arr[h_com]][index_box], dict_cen[str_num_arr[h_com+1]][index_box])\n",
    "#             aperture_3 = aperture_sum(r_3,counts_image[l,:,:], dict_cen[str_num_arr[h_com]][index_box], dict_cen[str_num_arr[h_com+1]][index_box])\n",
    "            \n",
    "# ## Area of aperture,\n",
    "#             area_1 = math.pi * r_1**2\n",
    "# ## Background in annulus from r_2 to r_3\n",
    "#             background_counts = aperture_3 - aperture_2\n",
    "# ## Area of Annulus\n",
    "#             area_2 = math.pi*(r_3**2 - r_2**2) #also known as npix\n",
    "# ## subtracting background: \n",
    "#             backgrnd_subtract = aperture_1 - background_counts*area_1/area_2\n",
    "#             ind_photometry_arr.append(backgrnd_subtract)\n",
    "#             phot_ap_arr.append(backgrnd_subtract)\n",
    "#             h_com = h_com+2\n",
    "\n",
    "# #         -----------------------------------------------\n",
    "# #         Time array\n",
    "\n",
    "#         ind_time_arr = []\n",
    "#         time_arr_func(time_arr,ind_time_arr,frame_t,bmjd_obs)\n",
    "\n",
    "# #         -----------------------------------------------\n",
    "# #         Saves it into an ascii array\n",
    "\n",
    "# #         print(num)\n",
    "# #         plt.plot(ind_time_arr,photometry_arr)\n",
    "# #         plt.plot(photometry_arr)\n",
    "\n",
    "#         if part_num==6:\n",
    "#             str_m='_part_6-1'\n",
    "#         elif part_num==7:\n",
    "#             str_m='_part_6-2'\n",
    "#         elif part_num==8:\n",
    "#             str_m='_part_7'\n",
    "#         else:\n",
    "#             str_m='_part_'+str(part_num)\n",
    "        \n",
    "#         word=ori_dir+'bcdfits_'+str(m)+str_m+'.txt'\n",
    "#         print(m)\n",
    "#         m+=1\n",
    "# #         plt.savefig(word)\n",
    "#         ind_arr_table = Table([ind_photometry_arr,ind_time_arr,centroid_com_arr_x,centroid_com_arr_y], names=[col_1,col_2,'x_com_cen','y_com_cen'])\n",
    "#         ascii.write(ind_arr_table, word, format='tab', fast_writer=False) \n",
    "# #         plt.show()    \n",
    "# #         -----------------------------------------------\n",
    "\n",
    "#     else:\n",
    "#         continue\n",
    "\n",
    "# if part_num==6:\n",
    "#     str_m='part_6-1'\n",
    "# elif part_num==7:\n",
    "#     str_m='part_6-2'\n",
    "# elif part_num==8:\n",
    "#     str_m='part_7'\n",
    "# else:\n",
    "#     str_m='part_'+str(part_num)\n",
    "\n",
    "\n",
    "# word=ori_dir+'bcdfits_'+str_m+'.txt'\n",
    "# Tot_arr_table = Table([phot_ap_arr,time_arr,cen_com_arr_x,cen_com_arr_y], names=[col_1,col_2,'x_com_cen','y_com_cen'])\n",
    "# ascii.write(Tot_arr_table, word, format='tab', fast_writer=False) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aug 15\n",
    "# def median_flux(ap_ph):\n",
    "#     ap_ph_med = ap_ph/np.nanmedian(ap_ph)\n",
    "#     return ap_ph_med\n",
    "# def plot_ascii(dir_lightcurv,col_1,col_2,part_str):\n",
    "#     data = ascii.read(dir_lightcurv)\n",
    "#     ap_phot = data[col_1]\n",
    "#     bmjd = data[col_2]\n",
    "#     ap_phot = median_flux(ap_phot)\n",
    "#     plt.plot(ap_phot,'.',label=part_str)\n",
    "# -------------------------------------------------\n",
    "# lightcurve_1=ori_dir+ 'bcdfits_part_'+str(part_num)+'.txt'\n",
    "# print(lightcurve_1)\n",
    "# plt.figure(figsize=(10,5))\n",
    "# # plt.ylim([290000,310000])\n",
    "# plt.ylim([.97,1.04])\n",
    "# # plt.xlim([-1,64*3])\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('Light Curve (Center of Mass)')\n",
    "# plot_ascii(lightcurve_1,col_1,col_2,'Part ...')\n",
    "\n",
    "# -------------------------------------------------\n",
    "\n",
    "# for filename in os.listdir(tot_dir_bcd[part_num-1]):\n",
    "#     if filename.endswith(\".fits\"): \n",
    "#         dir_bcd = os.path.join(tot_dir_bcd[part_num-1],filename)\n",
    "#         fits_file = fits.open(dir_bcd)             # Opens the directory of the bcd fits file.\n",
    "# #         fits_data = get_pkg_data_filename(dir_bcd) # Receives the data from the fits file directory.\n",
    "#         list_Primary = fits_file[0]                # Takes out Primary header from fits file.\n",
    "\n",
    "# #         Takes out specific information from the primary header.\n",
    "#         flux_conv= fits_file[0].header['FLUXCONV'] #Flux conversion\n",
    "#         bmjd_obs = fits_file[0].header['BMJD_OBS'] # Time measured as bmjd\n",
    "#         frame_t = fits_file[0].header['FRAMTIME']  # Frame time\n",
    "#         gain = fits_file[0].header['GAIN']         # The Gain\n",
    "#         exp_time= fits_file[0].header['EXPTIME']   \n",
    "#         print(str(filename))\n",
    "#         print('Exposure data: ',exp_time)\n",
    "# #         print('Flux Conv:',flux_conv )\n",
    "# #         print('Gain: ',gain)\n",
    "# #         print('Frame time: ',frame_t)\n",
    "# #         print('bmjd obs: ',bmjd_obs)\n",
    "#         print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug20\n",
    "# from fmpl_com_boxsize\n",
    "# # plt.title('aperture 1 with radius of '+ str(r_1));plt.plot(apPh_1,'.');plt.show()\n",
    "# # plt.title('aperture 2 with radius of '+ str(r_2));plt.plot(apPh_2,'.');plt.show()\n",
    "# # plt.title('aperture 3 with radius of '+ str(r_3));plt.plot(apPh_3,'.');plt.show()\n",
    "\n",
    "# def ap_range(fileseg,whole_or_part):\n",
    "# #     Used to view a certain amount of file segments \n",
    "#     fileseg=fileseg\n",
    "#     eqn = fileseg*64\n",
    "#     totval = eqn\n",
    "#     if whole_or_part =='Start':\n",
    "#         strt = 0\n",
    "#     elif whole_or_part == 'Part':\n",
    "#         strt = totval-64\n",
    "#     end = totval\n",
    "#     return(strt,end)\n",
    "\n",
    "# def remove_first_pixel_of_a_segm(ap_phot_arr):\n",
    "#     ap_phot_arr.pop(0)\n",
    "#     k=64\n",
    "#     del ap_phot_arr[k-1::k]\n",
    "\n",
    "# one = apPh_1[:]\n",
    "# two = apPh_2[:]\n",
    "# three = apPh_3[:]\n",
    "\n",
    "# remove_first_pixel_of_a_segm(three)\n",
    "# remove_first_pixel_of_a_segm(two)\n",
    "# remove_first_pixel_of_a_segm(one)\n",
    "\n",
    "\n",
    "# fileseg = 8\n",
    "# strt,end = ap_range(fileseg,'Start')\n",
    "# sli_apPh_1 = apPh_1[strt:end]\n",
    "# sli_apPh_2 = apPh_2[strt:end]\n",
    "# sli_apPh_3 = apPh_3[strt:end]\n",
    "\n",
    "# # plt.plot(sli_apPh_1,'.',label='ap_ph 1')\n",
    "# # plt.plot(sli_apPh_2,'.',label='ap_ph 2')\n",
    "# plt.plot(sli_apPh_3,'.',label='ap_ph 3')\n",
    "# plt.plot(three[strt:end],'.')\n",
    "# # plt.legend(loc='upper right');\n",
    "\n",
    "# print('median with ap phot of r_1:',np.median(sli_apPh_1))\n",
    "# print('median with ap phot of r_2:',np.median(sli_apPh_2))\n",
    "# print('median with ap phot of r_3:',np.median(sli_apPh_3))\n",
    "\n",
    "# # n=0\n",
    "# # print('\\n',apPh_1[n])\n",
    "# # print('\\n',apPh_2[n])\n",
    "# # print('\\n',apPh_3[n])\n",
    "# # print(strt,end)\n",
    "# -------------------------------------------------------------\n",
    "# def clip_of_mask_flux(clip_flux):\n",
    "#     clip = sigma_clip(clip_flux, sigma=sigma_num, sigma_lower=None, sigma_upper=None, iters=5, cenfunc=np.ma.median, stdfunc=np.std, axis=None, copy=True)\n",
    "#     clipped = clip[np.logical_not(clip.mask)]\n",
    "#     return clipped\n",
    "\n",
    "# def clip_of_mask (clp_med_flux, x):\n",
    "#     clip = sigma_clip(clp_med_flux, sigma=sigma_num, sigma_lower=None, sigma_upper=None, iters=5, cenfunc=np.ma.median, stdfunc=np.std, axis=None, copy=True)\n",
    "#     clipped_x = x[np.logical_not(clip.mask)]\n",
    "#     return clipped_x \n",
    "\n",
    "# from scipy.signal import medfilt\n",
    "# data_num = ascii.read(lightcurve_1)\n",
    "# # bmjd= data_num[col_2]\n",
    "# # bmjd= median_flux(bmjd)\n",
    "# ap_ph= data_num[col_1]\n",
    "# ap_ph= median_flux(ap_ph)\n",
    "# ap_ph=ap_ph[0:1000] \n",
    "# smooth_data = medfilt(ap_ph)\n",
    "# len(ap_ph)\n",
    "# plt.title('Original data');plt.plot(ap_ph,'.');plt.show()\n",
    "# plt.title('Original - smooth data');plt.plot(ap_ph-smooth_data,'.')\n",
    "# ori_minus_smooth = ap_ph-smooth_data\n",
    "# std_func = np.std(ori_minus_smooth)\n",
    "# print(std_func)\n",
    "# sigma_num=5\n",
    "# c_f =clip_of_mask_flux(ori_minus_smooth)\n",
    "# print(len(c_f))\n",
    "# plt.title('clipped data');plt.plot(c_f,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # yminN = 7500;ymaxN = 9800\n",
    "# # xminN = 0;xmaxN = 1000\n",
    "# # # minN = 300000; maxN = 700000\n",
    "# # # minN = 290000; maxN = 330000\n",
    "# # plt.title('aperture 1 with radius of '+ str(r_1));plt.ylim([yminN,ymaxN]);plt.xlim([xminN,xmaxN]);plt.plot(apPh_1,'');plt.show()\n",
    "# # plt.title('aperture 2 with radius of '+ str(r_2));plt.ylim([yminN,ymaxN]);plt.xlim([xminN,xmaxN]);plt.plot(apPh_2,'');plt.show()\n",
    "# # plt.title('aperture 3 with radius of '+ str(r_3));plt.ylim([yminN,ymaxN]);plt.xlim([xminN,xmaxN]);plt.plot(apPh_3,'');plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# def ap_range(fileseg,whole_or_part):\n",
    "# #     Used to view a certain amount of file segments \n",
    "#     fileseg=fileseg\n",
    "#     eqn = fileseg*64\n",
    "#     totval = eqn\n",
    "#     if whole_or_part =='Start':\n",
    "#         strt = 0\n",
    "#     elif whole_or_part == 'Part':\n",
    "#         strt = totval-64\n",
    "#     end = totval\n",
    "#     return(strt,end)\n",
    "# def median_flux(ap_ph):\n",
    "#     ap_ph_med = ap_ph/np.nanmedian(ap_ph)\n",
    "#     return ap_ph_med\n",
    "# def plot_ascii(dir_lightcurv,col_1,col_2,part_str):\n",
    "#     data = ascii.read(dir_lightcurv)\n",
    "#     ap_phot = data[col_1]\n",
    "#     bmjd = data[col_2]\n",
    "#     samp = ap_phot[:]\n",
    "#     ap_phot = median_flux(ap_phot)\n",
    "#     st,ed = ap_range(40,'Start')\n",
    "#     plt.plot(ap_phot,'.',label=part_str)\n",
    "# #     plt.plot(samp[st:ed],'.')\n",
    "\n",
    "\n",
    "    \n",
    "# samp= phot_ap_arr[:]\n",
    "# apPh_r1 = apPh_1[:]\n",
    "# apPh_r2 = apPh_2[:]\n",
    "# apPh_r3 = apPh_3[:]\n",
    "# # remove_first_pixel_of_a_segm(samp)\n",
    "\n",
    "# set_n = 11\n",
    "# st,ed = ap_range(set_n,'Part')\n",
    "# print(samp[st])\n",
    "\n",
    "# # lightcurve_1=ori_dir+ 'bcdfits_part_'+str(part_num)+'.txt'\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Number of data points')\n",
    "# plt.title('Aperture Photometry (1 data cube)'+'\\n in the '+str(set_n)+' data cube')\n",
    "# # This is the photometry in the course of one datacube \n",
    "# # We want to understand why the first data value in each datacube is found at a consistent value..\n",
    "# # plot_ascii(lightcurve_1,col_1,col_2,'Part ...')\n",
    "# # str1 = 'Radius One: '+str(r_1)\n",
    "# # str2 = 'Radius Two: '+str(r_2)\n",
    "# # str3 = 'Radius Three: '+str(r_3)\n",
    "# # plt.figtext(0.92,0.85,str1)\n",
    "# # plt.figtext(0.92,0.81,str2)\n",
    "# # plt.figtext(0.92,0.77,str3)\n",
    "# plt.ylim(440000,470000)\n",
    "# # plt.plot(apPh_r1[st:ed],'.')\n",
    "# # plt.plot(apPh_r2[st:ed],'.')\n",
    "# # plt.plot(apPh_r3[st:ed],'.')\n",
    "\n",
    "\n",
    "# # plt.plot(samp,'.')\n",
    "# plt.plot(samp[st:ed],'.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str1 = 'Radius One: '+str(r_1)\n",
    "# str2 = 'Radius Two: '+str(r_2)\n",
    "# str3 = 'Radius Three: '+str(r_3)\n",
    "# plt.figtext(0.92,0.85,str1)\n",
    "# plt.figtext(0.92,0.81,str2)\n",
    "# plt.figtext(0.92,0.77,str3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e92185718783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# print(np.mean(len_arr))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# ------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Flux'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of data points'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Aug 29\n",
    "# ## plots only Channel 2\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('CoM Channel 1 Light curve')\n",
    "# plt.plot(bin_h1,bin_f1,label='Part 1',color='tab:blue')\n",
    "# plt.plot(bin_h3,bin_f3,label='Part 3',color='tab:green')\n",
    "# plt.plot(bin_h6_1,bin_f6_1,label='Part 6-1',color='brown')\n",
    "# plt.plot(bin_h6_2,bin_f6_2,label='Part 6-2',color='pink')\n",
    "# plt.plot(bin_h7,bin_f7,label='Part 7',color='Grey')\n",
    "\n",
    "# ## plots only Channel 2\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('CoM Channel 2 Light curve')\n",
    "# plt.plot(bin_h2,bin_f2,color='tab:orange')\n",
    "# plt.plot(bin_h4,bin_f4,color='tab:red')\n",
    "# plt.plot(bin_h5,bin_f5,color='tab:purple')\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.title('Light Curve (Center of Mass)')\n",
    "# plt.xlabel('time')\n",
    "# plt.ylabel('flux')\n",
    "\n",
    "# plt.plot(bin_h1,bin_f1,label='CH1 Part 1',color='tab:blue')\n",
    "# plt.plot(bin_h2,bin_f2,label='CH2 Part 2',color='tab:orange')\n",
    "# plt.plot(bin_h3,bin_f3,label='CH1 Part 3',color='tab:green')\n",
    "# plt.plot(bin_h4,bin_f4,label='CH2 Part 4',color='tab:red')\n",
    "# plt.plot(bin_h5,bin_f5,label='CH2Part 5',color='tab:purple')\n",
    "# plt.plot(bin_h6_1,bin_f6_1,label='CH1 Part 6-1',color='brown')\n",
    "# plt.plot(bin_h6_2,bin_f6_2,label='CH1 Part 6-2',color='pink')\n",
    "# plt.plot(bin_h7,bin_f7,label='CH1 Part 7',color='Grey')\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# ----\n",
    "# num = np.linspace(1,val_range-1,val_range-1)\n",
    "# print(num)\n",
    "\n",
    "# -----\n",
    "# import pickle\n",
    "# # with open(filename, wb) as f:\n",
    "# #     pickle.dump(your_content, f)\n",
    "# # with open(filename, rb) as f:\n",
    "# #     var_you_want_to_load_into = pickle.load(f)\n",
    "\n",
    "# name = 'CEN_2DG_7x7_prt'+str(part_num)+'.pickle'\n",
    "\n",
    "# # name_2 = 'CEN_2DG_7x7.pickle'\n",
    "# with open(name, 'wb') as f:\n",
    "#     pickle.dump([phot_ap_arr,time_arr,cen_2dg_arr_x,cen_2dg_arr_y], f)\n",
    "\n",
    "# with open(name, 'rb') as f:\n",
    "#     phot_ap_arr,time_arr,cen_2dg_arr_x,cen_2dg_arr_y= pickle.load(f)\n",
    "\n",
    "# --------\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Number of data points')\n",
    "# plt.title('Aperture Photometry')\n",
    "# plt.ylim(440000,470000);\n",
    "# plt.plot(samp,'.')\n",
    "# for n in range(len(samp)):\n",
    "#     print(samp)\n",
    "# len_arr = []\n",
    "# # Checks the average of every first value of each datacube(one data cube has 64 aperture photometry values)\n",
    "# # print(samp[0],'\\n...')\n",
    "# for n in range(295):\n",
    "# #     n=64\n",
    "#     st,ed = ap_range(n,'Part')\n",
    "# #     print(st,ed)\n",
    "#     len_arr.append(samp[ed])\n",
    "# #     print(samp[ed])\n",
    "\n",
    "# print(len(len_arr))\n",
    "# print(np.mean(len_arr))\n",
    "# ------\n",
    "#         plt.plot(ind_time_arr,photometry_arr)\n",
    "#         plt.plot(photometry_arr)\n",
    "# ------\n",
    "# def plot_ascii(dir_lightcurv,col_1,col_2,part_str):\n",
    "#     data = ascii.read(dir_lightcurv)\n",
    "#     ap_phot = data[col_1]\n",
    "#     bmjd = data[col_2]\n",
    "#     samp = ap_phot[:]\n",
    "#     ap_phot = median_flux(ap_phot)\n",
    "# #     st,ed = ap_range(40,'Start')\n",
    "#     plt.plot(ap_phot,'.',label=part_str)\n",
    "# #     plt.plot(samp[st:ed],'.')\n",
    "# ----\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Number of data points')\n",
    "# plt.title('Aperture Photometry')\n",
    "# plt.ylim(440000,470000);\n",
    "# plt.plot(samp,'.')\n",
    "# for n in range(len(samp)):\n",
    "#     print(samp)\n",
    "# len_arr = []\n",
    "# # Checks the average of every first value of each datacube(one data cube has 64 aperture photometry values)\n",
    "# # print(samp[0],'\\n...')\n",
    "# for n in range(295):\n",
    "# #     n=64\n",
    "#     st,ed = ap_range(n,'Part')\n",
    "# #     print(st,ed)\n",
    "#     len_arr.append(samp[ed])\n",
    "# #     print(samp[ed])\n",
    "\n",
    "# print(len(len_arr))\n",
    "# print(np.mean(len_arr))\n",
    "# ------\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.ylabel('Flux')\n",
    "plt.xlabel('Number of data points')\n",
    "plt.title('Aperture Photometry')\n",
    "plt.ylim(440000,470000);\n",
    "plt.plot(samp,'.')\n",
    "# for n in range(len(samp)):\n",
    "#     print(samp)\n",
    "len_arr = []\n",
    "# Checks the average of every first value of each datacube(one data cube has 64 aperture photometry values)\n",
    "# print(samp[0],'\\n...')\n",
    "for n in range(280):\n",
    "#     n=64\n",
    "    st,ed = ap_range(n,'Part')\n",
    "#     print(st,ed)\n",
    "    len_arr.append(samp[ed])\n",
    "#     print(samp[ed])\n",
    "\n",
    "print(len(len_arr))\n",
    "print(np.mean(len_arr))\n",
    "# -----\n",
    "# plt.plot(bmjd_1,ap_ph_1,'.',label='CH1 Part 1')\n",
    "# plt.plot(bmjd_2,ap_ph_2,'.',label='CH2 Part 2')\n",
    "# plt.plot(bmjd_3,ap_ph_3,'.',label='CH1 Part 3')\n",
    "# plt.plot(bmjd_4,ap_ph_4,'.',label='CH2 Part 4')\n",
    "# plt.plot(bmjd_5,ap_ph_5,'.',label='CH2 Part 5')\n",
    "# plt.plot(bmjd_6_1,ap_ph_6_1,'.',label='CH1 Part 6-1')\n",
    "# plt.plot(bmjd_6_2,ap_ph_6_2,'.',label='CH1 Part 6-2')\n",
    "# plt.plot(bmjd_7,ap_ph_7,'.',label='CH1 Part 7')\n",
    "# ---------\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('Light Curve (Center of Mass)')\n",
    "\n",
    "## Clips or masks the data within the array.\n",
    "##  for both channel 1 and channel 2\n",
    "c_f1,c_h1 = clip_arr(ap_ph_1,bmjd_1,sigma_num,'CH1 Part 1','tab:blue')\n",
    "c_f2,c_h2 = clip_arr(ap_ph_2,bmjd_2,sigma_num,'CH2 Part 2','tab:orange')\n",
    "c_f3,c_h3 = clip_arr(ap_ph_3,bmjd_3,sigma_num,'CH1 Part 3','tab:green')\n",
    "c_f4,c_h4 = clip_arr(ap_ph_4,bmjd_4,sigma_num,'CH2 Part 4','tab:red')\n",
    "# c_f5,c_h5 = clip_arr(ap_ph_5,bmjd_5,sigma_num,'CH2 Part 5','tab:purple')\n",
    "# c_f6_1,c_h6_1 = clip_arr(ap_ph_6_1,bmjd_6_1,sigma_num,'CH1 Part 6-1','tab:brown')\n",
    "# c_f6_2,c_h6_2 = clip_arr(ap_ph_6_2,bmjd_6_2,sigma_num,'CH1 Part 6-2','tab:pink')\n",
    "# c_f7,c_h7 = clip_arr(ap_ph_7,bmjd_7,sigma_num,'CH1 Part 7','tab:grey')\n",
    "# # plt.legend(loc='lower left')\n",
    "\n",
    "# ## Printing out the length of clipped and whole array\n",
    "print('Part 1 (Blue):',len(c_f1),len(ap_ph_1))\n",
    "print('Part 2 (Orange):',len(c_f2),len(ap_ph_2))\n",
    "print('Part 3 (Green):',len(c_f3),len(ap_ph_3))\n",
    "print('Part 4 (Red):',len(c_f4),len(ap_ph_4))\n",
    "# print('Part 5 (Purple):',len(c_f5),len(ap_ph_5))\n",
    "# print('Part 6_1 (Brown):',len(c_f6_1),len(ap_ph_6_1))\n",
    "# print('Part 6_2 (Pink):',len(c_f6_2),len(ap_ph_6_2))\n",
    "# print('Part 7 (Grey):',len(c_f7),len(ap_ph_7))\n",
    "\n",
    "# ## plots only Channel 1\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('CoM Channel 1 Light curve')\n",
    "# c_f1,c_h1 = clip_arr(ap_ph_1,bmjd_1,sigma_num,'CH1 Part 1','tab:blue')\n",
    "# c_f3,c_h3 = clip_arr(ap_ph_3,bmjd_3,sigma_num,'CH1 Part 3','tab:green')\n",
    "# c_f6_1,c_h6_1 = clip_arr(ap_ph_6_1,bmjd_6_1,sigma_num,'CH1 Part 6-1','tab:brown')\n",
    "# c_f6_2,c_h6_2 = clip_arr(ap_ph_6_2,bmjd_6_2,sigma_num,'CH1 Part 6-2','tab:pink')\n",
    "# c_f7,c_h7 = clip_arr(ap_ph_7,bmjd_7,sigma_num,'CH1 Part 7','tab:grey')\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "# ## plots only Channel 2\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('CoM Channel 2 Light curve')\n",
    "# c_f2,c_h2 = clip_arr(ap_ph_2,bmjd_2,sigma_num,'CH2 Part 2','tab:orange')\n",
    "# c_f4,c_h4 = clip_arr(ap_ph_4,bmjd_4,sigma_num,'CH2 Part 4','tab:red')\n",
    "# c_f5,c_h5 = clip_arr(ap_ph_5,bmjd_5,sigma_num,'CH2 Part 5','tab:purple')\n",
    "# plt.legend(loc='upper right')\n",
    "# ------\n",
    "\n",
    "\n",
    "##c_f:clipped flux of original aperture photometry array\n",
    "##c_h:clipped time of the flux\n",
    "\n",
    "sigma_num=5\n",
    "# # data = c_f1.data\n",
    "nbin_num = 10\n",
    "\n",
    "# # bins = len(data) //next this and the next lines of code are found within the def function create above.\n",
    "# # binned_data = [np.mean(data[i*nbin:i*nbin+nbin]) for i in range(1,bins//nbin+1)]\n",
    "nbin_num = 10\n",
    "bin_f1 = bin_funct(c_f1,nbin_num)\n",
    "bin_h1 = bin_funct(c_h1,nbin_num)\n",
    "# bin_f2 = bin_funct(c_f2,nbin_num)\n",
    "# bin_h2 = bin_funct(c_h2,nbin_num)\n",
    "# bin_f3 = bin_funct(c_f3,nbin_num)\n",
    "# bin_h3 =bin_funct(c_h3,nbin_num)\n",
    "# bin_f4 = bin_funct(c_f4,nbin_num)\n",
    "# bin_h4 = bin_funct(c_h4,nbin_num)\n",
    "# bin_f5 = bin_funct(c_f5,nbin_num)\n",
    "# bin_h5 = bin_funct(c_h5,nbin_num)\n",
    "# bin_f6_1 = bin_funct(c_f6_1,nbin_num)\n",
    "# bin_h6_1 = bin_funct(c_h6_1,nbin_num)\n",
    "# bin_f6_2 = bin_funct(c_f6_2,nbin_num)\n",
    "# bin_h6_2 = bin_funct(c_h6_2,nbin_num)\n",
    "# bin_f7 = bin_funct(c_f7,nbin_num)\n",
    "# bin_h7 = bin_funct(c_h7,nbin_num)\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.title('Light Curve (Center of Mass)')\n",
    "# plt.xlabel('time')\n",
    "# plt.ylabel('flux')\n",
    "\n",
    "# plt.plot(bin_h1,bin_f1,label='CH1 Part 1',color='tab:blue')\n",
    "# plt.plot(bin_h2,bin_f2,label='CH2 Part 2',color='tab:orange')\n",
    "# plt.plot(bin_h3,bin_f3,label='CH1 Part 3',color='tab:green')\n",
    "# plt.plot(bin_h4,bin_f4,label='CH2 Part 4',color='tab:red')\n",
    "# plt.plot(bin_h5,bin_f5,label='CH2Part 5',color='tab:purple')\n",
    "# plt.plot(bin_h6_1,bin_f6_1,label='CH1 Part 6-1',color='brown')\n",
    "# plt.plot(bin_h6_2,bin_f6_2,label='CH1 Part 6-2',color='pink')\n",
    "# plt.plot(bin_h7,bin_f7,label='CH1 Part 7',color='Grey')\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# ## plots only Channel 2\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('CoM Channel 1 Light curve')\n",
    "# plt.plot(bin_h1,bin_f1,label='Part 1',color='tab:blue')\n",
    "# plt.plot(bin_h3,bin_f3,label='Part 3',color='tab:green')\n",
    "# plt.plot(bin_h6_1,bin_f6_1,label='Part 6-1',color='brown')\n",
    "# plt.plot(bin_h6_2,bin_f6_2,label='Part 6-2',color='pink')\n",
    "# plt.plot(bin_h7,bin_f7,label='Part 7',color='Grey')\n",
    "\n",
    "# ## plots only Channel 2\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.ylabel('Flux')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('CoM Channel 2 Light curve')\n",
    "# plt.plot(bin_h2,bin_f2,color='tab:orange')\n",
    "# plt.plot(bin_h4,bin_f4,color='tab:red')\n",
    "# plt.plot(bin_h5,bin_f5,color='tab:purple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_flux(ap_ph):\n",
    "    ap_ph_med = ap_ph/np.nanmedian(ap_ph)\n",
    "    return ap_ph_med\n",
    "def receive_ascii_data(dir_lightcurv,part_str):\n",
    "    col_1='AperturePhot'\n",
    "    col_2='bmjd'\n",
    "    col_3='x_com_cen'\n",
    "    col_4='y_com_cen'\n",
    "    data = ascii.read(dir_lightcurv)\n",
    "    ap_phot = data[col_1]\n",
    "    bmjd = data[col_2]\n",
    "    xcen=data[col_3]\n",
    "    ycen=data[col_4]\n",
    "    ap_phot = median_flux(ap_phot)\n",
    "    plt.plot(bmjd,ap_phot,'.',label=part_str)\n",
    "    return(ap_phot,bmjd,xcen,ycen)\n",
    "def clip_of_mask_flux(clip_flux):\n",
    "    clip = sigma_clip(clip_flux, sigma=sigma_num, sigma_lower=None, sigma_upper=None, iters=5, cenfunc=np.ma.median, stdfunc=np.std, axis=None, copy=True)\n",
    "    clipped = clip[np.logical_not(clip.mask)] - 1.\n",
    "    return clipped\n",
    "\n",
    "def clip_of_mask (clp_med_flux, x):\n",
    "    clip = sigma_clip(clp_med_flux, sigma=sigma_num, sigma_lower=None, sigma_upper=None, iters=5, cenfunc=np.ma.median, stdfunc=np.std, axis=None, copy=True)\n",
    "    clipped_x = x[np.logical_not(clip.mask)]\n",
    "    return clipped_x  \n",
    "\n",
    "def clip_arr(data,time,sigma_num,label_nme,colorpnts):\n",
    "#     Calls previous definition functions and plots them\n",
    "#     This is to make the code more neater.\n",
    "    clip_flux = clip_of_mask_flux(data)\n",
    "    clip_time = clip_of_mask(data,time)\n",
    "#     plt.plot(clip_time,clip_flux,'.',label=label_nme,color=colorpnts,)\n",
    "    return clip_flux,clip_time\n",
    "\n",
    "def bin_funct(data_arr,nbin):\n",
    "    data= data_arr.data\n",
    "    bins=len(data)\n",
    "    binned_data = [np.mean(data[i*nbin:i*nbin+nbin]) for i in range(1,bins//nbin+1)]\n",
    "    return binned_data\n",
    "def choose_fourier(nmode):\n",
    "    def fourier_model(x,*fp):\n",
    "        fourier = fp[1] ##setting the offset first.\n",
    "#         print(fourier)\n",
    "        for i in range(nmode):\n",
    "            n=i+1\n",
    "            fourier = fourier + fp[2+i*2]*np.cos(2.*np.pi*n*x/fp[0]) + fp[3+i*2]*np.sin(2.*np.pi*n*x/fp[0])\n",
    "        return(fourier)\n",
    "    return(fourier_model)\n",
    "\n",
    "# def choose_fourier1(nmode):\n",
    "#     def fourier_model(x,*fp):\n",
    "#         fourier = fp[1] ##setting the offset first.\n",
    "# #         print(fourier)\n",
    "#         for i in range(nmode+1):\n",
    "#             n=i\n",
    "#             fourier = fourier + fp[2+i*2]*np.cos(2.*np.pi*n*x/fp[0]) + fp[3+i*2]*np.sin(2.*np.pi*n*x/fp[0])\n",
    "#         return(fourier)\n",
    "#     return(fourier_model)\n",
    "\n",
    "def choose_ipsv(maxorder):\n",
    "    def ipsv_model(xy_arr,*p):\n",
    "        x=xy_arr[0,:]\n",
    "        y=xy_arr[1,:]\n",
    "        x_bar=np.mean(xy_arr[0,:])\n",
    "        y_bar=np.mean(xy_arr[1,:])\n",
    "        \n",
    "        index_ipsv = 1\n",
    "        ipsv = p[0]\n",
    "        for i in range(maxorder):\n",
    "            order=i+1\n",
    "            loop_order=i+2\n",
    "            for j in range(loop_order):\n",
    "                ipsv=ipsv+p[index_ipsv]*(x-x_bar)**(order-j)*(y-y_bar)**(j)\n",
    "                index_ipsv=index_ipsv+1\n",
    "#         print(index_ipsv)\n",
    "        return(ipsv)\n",
    "    return(ipsv_model)\n",
    "\n",
    "def choose_f_ipsv(nmodes,maxorder):\n",
    "    def f_ipsv_model(xyt_arr,*p):\n",
    "        x=xyt_arr[0,:]\n",
    "        y=xyt_arr[1,:]\n",
    "        t=xyt_arr[2,:]\n",
    "        xy = np.array([x,y])\n",
    "#       functions to find the number of parameters for each model.\n",
    "        n_ipsv=1\n",
    "        for i in range(maxorder):#parameters for ipsv\n",
    "            n_ipsv=n_ipsv +(i+2) \n",
    "            \n",
    "        n_f = 2+2*(nmodes) #parameters for fourier\n",
    "#         print(n_f,n_ipsv)\n",
    "#       splitting up actual parameter ( p ) according to model (ipsv then fourier parameters)\n",
    "        p_ipsv = p[0:n_ipsv]\n",
    "        p_f = p[n_ipsv::]\n",
    "#         print(p)\n",
    "        ipsv_model = choose_ipsv(maxorder)(xy,*p_ipsv)\n",
    "        f_model = choose_fourier(nmodes)(t,*p_f)\n",
    "        model = ipsv_model *f_model\n",
    "        return(model)\n",
    "    return(f_ipsv_model)\n",
    "\n",
    "def organize_data(lightcurve):\n",
    "    data_num = ascii.read(lightcurve)\n",
    "    #saves in all data into a table array\n",
    "    col_1='AperturePhot';col_2='bmjd';col_3='x_com_cen';col_4='y_com_cen'\n",
    "    ap_ph = data_num[col_1]\n",
    "    bmjd = data_num[col_2]\n",
    "    x_cen=data_num[col_3]\n",
    "    y_cen=data_num[col_4]\n",
    "    \n",
    "#     takes the median of the flux\n",
    "    ap_ph=median_flux(ap_ph)\n",
    "#     Clips out data points from\n",
    "#      the lightcurve along with its\n",
    "#      centroids and time.\n",
    "#     c_f:clipped flux of original aperture photometry array\n",
    "#     c_h:clipped time of the flux\n",
    "    c_f =clip_of_mask(ap_ph,ap_ph)\n",
    "    c_h = clip_of_mask(ap_ph,bmjd)\n",
    "    c_cenx = clip_of_mask(ap_ph,x_cen)\n",
    "    c_ceny = clip_of_mask(ap_ph,y_cen)\n",
    "    \n",
    "#     c_fbin = bin_funct(c_f,nbin_num);c_f = c_fbin\n",
    "#     c_hbin = bin_funct(c_h,nbin_num);c_h = c_hbin\n",
    "#     c_cenxbin = bin_funct(c_cenx,nbin_num);c_cenx = c_cenxbin\n",
    "#     c_cenybin = bin_funct(c_ceny,nbin_num);c_ceny = c_cenybin\n",
    "    \n",
    "    arr=np.array([c_f,c_h,c_cenx,c_ceny])\n",
    "    return(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apPhot_range(fileseg,str_whole_or_part):\n",
    "# #     Used to view a certain amount of file segments \n",
    "#     fileseg=fileseg\n",
    "#     eqn = fileseg*64\n",
    "#     totval = eqn\n",
    "#     if str_whole_or_part =='Start':\n",
    "#         strt = 0\n",
    "#     elif str_whole_or_part == 'Part':\n",
    "#         strt = totval-64\n",
    "#     end = totval\n",
    "#     return(strt,end)\n",
    "# st,ed = apPhot_range(300,'Start')\n",
    "# plt.plot(model_final[st:ed],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # data = Table({'a': [1, 2, 3],'b': [4.0, 5.0, 6.0]},names=['a', 'b'])\n",
    "# # ascii.write(data)\n",
    "# # data = np.array([(1, 2., 'Hello'), (2, 3., \"World\")],dtype=('i4,f4,a10'))\n",
    "# # ascii.write(data)\n",
    "# word='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/'+'full_LightCurve'+'.txt'\n",
    "# data = Table([full_light_curve])\n",
    "# ascii.write(data,word, format='tab', fast_writer=False)\n",
    "# # Tot_arr_table = Table([sliced_paa,sliced_time,sliced_cenx,sliced_ceny], names=[col_1,col_2,'x_com_cen','y_com_cen'])\n",
    "# # ascii.write(Tot_arr_table, word, format='tab', fast_writer=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sept5\n",
    "# ap_ph_list.append(ap_ph_6_2);ap_ph_list.append(ap_ph_3);ap_ph_list.append(ap_ph_5);ap_ph_list.append(ap_ph_1)\n",
    "# ap_ph_list.append(ap_ph_4);ap_ph_list.append(ap_ph_7);ap_ph_list.append(ap_ph_2);ap_ph_list.append(ap_ph_6_1)\n",
    "# bmjd_list =[]\n",
    "# full_bmjd = []\n",
    "# bmjd_list.append(bmjd_6_2);bmjd_list.append(bmjd_3);bmjd_list.append(bmjd_5);bmjd_list.append(bmjd_1)\n",
    "# bmjd_list.append(bmjd_4);bmjd_list.append(bmjd_7);bmjd_list.append(bmjd_2);bmjd_list.append(bmjd_6_1)\n",
    "# xcen_list =[]\n",
    "# full_xcen= []\n",
    "# xcen_list.append(x_cen6_2);xcen_list.append(x_cen3);xcen_list.append(x_cen5);xcen_list.append(x_cen1)\n",
    "# xcen_list.append(x_cen4);xcen_list.append(x_cen7);xcen_list.append(x_cen2);xcen_list.append(x_cen6_1)\n",
    "# ycen_list =[]\n",
    "# full_ycen=[]\n",
    "# ycen_list.append(y_cen6_2);ycen_list.append(y_cen3);ycen_list.append(y_cen5);ycen_list.append(y_cen1)\n",
    "# ycen_list.append(y_cen4);ycen_list.append(y_cen7);ycen_list.append(y_cen2);ycen_list.append(y_cen6_1)\n",
    "\n",
    "# full_arr_func(ap_ph_list,full_light_curve)\n",
    "# full_arr_func(bmjd_list,full_bmjd)\n",
    "# full_arr_func(xcen_list,full_xcen)\n",
    "# full_arr_func(ycen_list,full_ycen)\n",
    "# -----------------------------------------\n",
    "# def median_flux(ap_ph):\n",
    "#     ap_ph_med = ap_ph/np.nanmedian(ap_ph)\n",
    "#     return ap_ph_med\n",
    "# def receive_ascii_data(dir_lightcurv,part_str):\n",
    "#     col_1='AperturePhot'\n",
    "#     col_2='bmjd'\n",
    "#     col_3='x_com_cen'\n",
    "#     col_4='y_com_cen'\n",
    "#     data = ascii.read(dir_lightcurv)\n",
    "#     ap_phot = data[col_1]\n",
    "#     bmjd = data[col_2]\n",
    "#     xcen=data[col_3]\n",
    "#     ycen=data[col_4]\n",
    "#     ap_phot = median_flux(ap_phot)\n",
    "#     plt.plot(bmjd,ap_phot,'.',label=part_str)\n",
    "#     return(ap_phot,bmjd,xcen,ycen)\n",
    "# def clip_of_mask_flux(clip_flux):\n",
    "#     clip = sigma_clip(clip_flux, sigma=sigma_num, sigma_lower=None, sigma_upper=None, iters=5, cenfunc=np.ma.median, stdfunc=np.std, axis=None, copy=True)\n",
    "#     clipped = clip[np.logical_not(clip.mask)] - 1.\n",
    "#     return clipped\n",
    "\n",
    "# def clip_of_mask (clp_med_flux, x):\n",
    "#     clip = sigma_clip(clp_med_flux, sigma=sigma_num, sigma_lower=None, sigma_upper=None, iters=5, cenfunc=np.ma.median, stdfunc=np.std, axis=None, copy=True)\n",
    "#     clipped_x = x[np.logical_not(clip.mask)]\n",
    "#     return clipped_x  \n",
    "\n",
    "# def clip_arr(data,time,sigma_num,label_nme,colorpnts):\n",
    "# #     Calls previous definition functions and plots them\n",
    "# #     This is to make the code more neater.\n",
    "#     clip_flux = clip_of_mask_flux(data)\n",
    "#     clip_time = clip_of_mask(data,time)\n",
    "# #     plt.plot(clip_time,clip_flux,'.',label=label_nme,color=colorpnts,)\n",
    "#     return clip_flux,clip_time\n",
    "\n",
    "# def bin_funct(data_arr,nbin):\n",
    "#     data= data_arr.data\n",
    "#     bins=len(data)\n",
    "#     binned_data = [np.mean(data[i*nbin:i*nbin+nbin]) for i in range(1,bins//nbin+1)]\n",
    "#     return binned_data\n",
    "# def choose_fourier(nmode):\n",
    "#     def fourier_model(x,*fp):\n",
    "#         fourier = fp[1] ##setting the offset first.\n",
    "# #         print(fourier)\n",
    "#         for i in range(nmode):\n",
    "#             n=i+1\n",
    "#             fourier = fourier + fp[2+i*2]*np.cos(2.*np.pi*n*x/fp[0]) + fp[3+i*2]*np.sin(2.*np.pi*n*x/fp[0])\n",
    "#         return(fourier)\n",
    "#     return(fourier_model)\n",
    "\n",
    "# # def choose_fourier1(nmode):\n",
    "# #     def fourier_model(x,*fp):\n",
    "# #         fourier = fp[1] ##setting the offset first.\n",
    "# # #         print(fourier)\n",
    "# #         for i in range(nmode+1):\n",
    "# #             n=i\n",
    "# #             fourier = fourier + fp[2+i*2]*np.cos(2.*np.pi*n*x/fp[0]) + fp[3+i*2]*np.sin(2.*np.pi*n*x/fp[0])\n",
    "# #         return(fourier)\n",
    "# #     return(fourier_model)\n",
    "\n",
    "# def choose_ipsv(maxorder):\n",
    "#     def ipsv_model(xy_arr,*p):\n",
    "#         x=xy_arr[0,:]\n",
    "#         y=xy_arr[1,:]\n",
    "#         x_bar=np.mean(xy_arr[0,:])\n",
    "#         y_bar=np.mean(xy_arr[1,:])\n",
    "        \n",
    "#         index_ipsv = 1\n",
    "#         ipsv = p[0]\n",
    "#         for i in range(maxorder):\n",
    "#             order=i+1\n",
    "#             loop_order=i+2\n",
    "#             for j in range(loop_order):\n",
    "#                 ipsv=ipsv+p[index_ipsv]*(x-x_bar)**(order-j)*(y-y_bar)**(j)\n",
    "#                 index_ipsv=index_ipsv+1\n",
    "# #         print(index_ipsv)\n",
    "#         return(ipsv)\n",
    "#     return(ipsv_model)\n",
    "\n",
    "# def choose_f_ipsv(nmodes,maxorder):\n",
    "#     def f_ipsv_model(xyt_arr,*p):\n",
    "#         x=xyt_arr[0,:]\n",
    "#         y=xyt_arr[1,:]\n",
    "#         t=xyt_arr[2,:]\n",
    "#         xy = np.array([x,y])\n",
    "# #       functions to find the number of parameters for each model.\n",
    "#         n_ipsv=1\n",
    "#         for i in range(maxorder):#parameters for ipsv\n",
    "#             n_ipsv=n_ipsv +(i+2) \n",
    "            \n",
    "#         n_f = 2+2*(nmodes) #parameters for fourier\n",
    "# #         print(n_f,n_ipsv)\n",
    "# #       splitting up actual parameter ( p ) according to model (ipsv then fourier parameters)\n",
    "#         p_ipsv = p[0:n_ipsv]\n",
    "#         p_f = p[n_ipsv::]\n",
    "# #         print(p)\n",
    "#         ipsv_model = choose_ipsv(maxorder)(xy,*p_ipsv)\n",
    "#         f_model = choose_fourier(nmodes)(t,*p_f)\n",
    "#         model = ipsv_model *f_model\n",
    "#         return(model)\n",
    "#     return(f_ipsv_model)\n",
    "\n",
    "# def organize_data(lightcurve):\n",
    "#     data_num = ascii.read(lightcurve)\n",
    "#     #saves in all data into a table array\n",
    "#     col_1='AperturePhot';col_2='bmjd';col_3='x_com_cen';col_4='y_com_cen'\n",
    "#     ap_ph = data_num[col_1]\n",
    "#     bmjd = data_num[col_2]\n",
    "#     x_cen=data_num[col_3]\n",
    "#     y_cen=data_num[col_4]\n",
    "    \n",
    "# #     takes the median of the flux\n",
    "#     ap_ph=median_flux(ap_ph)\n",
    "# #     Clips out data points from\n",
    "# #      the lightcurve along with its\n",
    "# #      centroids and time.\n",
    "# #     c_f:clipped flux of original aperture photometry array\n",
    "# #     c_h:clipped time of the flux\n",
    "#     c_f =clip_of_mask(ap_ph,ap_ph)\n",
    "#     c_h = clip_of_mask(ap_ph,bmjd)\n",
    "#     c_cenx = clip_of_mask(ap_ph,x_cen)\n",
    "#     c_ceny = clip_of_mask(ap_ph,y_cen)\n",
    "    \n",
    "# #     c_fbin = bin_funct(c_f,nbin_num);c_f = c_fbin\n",
    "# #     c_hbin = bin_funct(c_h,nbin_num);c_h = c_hbin\n",
    "# #     c_cenxbin = bin_funct(c_cenx,nbin_num);c_cenx = c_cenxbin\n",
    "# #     c_cenybin = bin_funct(c_ceny,nbin_num);c_ceny = c_cenybin\n",
    "    \n",
    "#     arr=np.array([c_f,c_h,c_cenx,c_ceny])\n",
    "#     return(arr)\n",
    "# ------\n",
    "# full_data=ascii.read(word)\n",
    "# f_ap_ph = full_data['AperturePhot']\n",
    "# f_bmjd=full_data['bmjd']\n",
    "# f_xcen = full_data['x_com_cen']\n",
    "# f_ycen = full_data['y_com_cen']\n",
    "# -----\n",
    "# nbin_num = 35\n",
    "# bin_f = bin_funct(c_f,nbin_num)\n",
    "# bin_h = bin_funct(c_h,nbin_num)\n",
    "# len(bin_f)\n",
    "# plt.plot(bin_f,'.')\n",
    "# # plt.plot(c_f,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sept 9\n",
    "\n",
    "##     Clips out data points from\n",
    "##      the lightcurve along with its\n",
    "##      centroids and time.\n",
    "###      c_f:clipped flux of original aperture photometry array\n",
    "###      c_h:clipped time of the flux\n",
    "#     c_f =clip_of_mask(ap_ph,ap_ph)\n",
    "#     c_h = clip_of_mask(ap_ph,bmjd)\n",
    "#     c_cenx = clip_of_mask(ap_ph,x_cen)\n",
    "#     c_ceny = clip_of_mask(ap_ph,y_cen)\n",
    "    \n",
    "#     c_fbin = bin_funct(c_f,nbin_num);c_f = c_fbin\n",
    "#     c_hbin = bin_funct(c_h,nbin_num);c_h = c_hbin\n",
    "#     c_cenxbin = bin_funct(c_cenx,nbin_num);c_cenx = c_cenxbin\n",
    "#     c_cenybin = bin_funct(c_ceny,nbin_num);c_ceny = c_cenybin\n",
    "\n",
    "\n",
    "# sept 11\n",
    "\n",
    "# -----\n",
    "# # Take the clip of the data one more time\n",
    "# sigma_num=3\n",
    "# c2_f =clip_of_mask(c_f,c_f)\n",
    "# c2_h = clip_of_mask(c_f,c_h)\n",
    "# c2_cenx = clip_of_mask(c_f,c_xcen)\n",
    "# c2_ceny = clip_of_mask(c_f,c_ycen)\n",
    "# xyt_arr=np.array([c2_cenx,c2_ceny,c2_h])\n",
    "# xy_arr=np.array([c2_cenx,c2_ceny])\n",
    "# full_params, covar = curve_fit(choose_f_ipsv(nmodes,maxorder),xyt_arr,c2_f,p0=guess_ipsv_f)\n",
    "# fullp_ipsv = full_params[0:n_ipsv]\n",
    "# fullp_f = full_params[n_ipsv::]\n",
    "\n",
    "# model_f2 = choose_fourier(nmodes)(c_h,*fullp_f)\n",
    "# model_ipsv2 = choose_ipsv(maxorder)(xy_arr,*fullp_ipsv)\n",
    "# model_final2 = choose_f_ipsv(nmodes,maxorder)(xyt_arr,*full_params)\n",
    "# flux_w_no_ipsv_2 = c2_f/model_ipsv2\n",
    "# plt.plot(c2_h,flux_w_no_ipsv_2,'.')\n",
    "# ---------\n",
    "# print(len(c_h),len(c2_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sept 11\n",
    "# -----------------------\n",
    "# with open(filename, wb) as f:\n",
    "#     pickle.dump(your_content, f)\n",
    "# with open(filename, rb) as f:\n",
    "#     var_you_want_to_load_into = pickle.load(f)\n",
    "# ----------------------\n",
    "# dir_pickl_array =['/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/pickle_LC/pickle_lightcurve_1.pickle',\n",
    "#                   '/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/pickle_LC/pickle_lightcurve_2.pickle',\n",
    "#                   '/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/pickle_LC/pickle_lightcurve_3.pickle',\n",
    "#                   '/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/pickle_LC/pickle_lightcurve_4.pickle',\n",
    "#                   '/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/pickle_LC/pickle_lightcurve_5.pickle',\n",
    "#                   '/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/pickle_LC/pickle_lightcurve_6_2.pickle',\n",
    "#                   '/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/pickle_LC/pickle_lightcurve_7.pickle']\n",
    "# # part_num=0\n",
    "# # with open(dir_pickl_array[part_num], 'rb') as f:\n",
    "# #     f_1,b,x,d= pickle.load(f)\n",
    "\n",
    "# def pickle_reader(dir_array,part_num):\n",
    "#     with open(dir_array[part_num], 'rb') as f:\n",
    "#         f,h,cenx,ceny= pickle.load(f)\n",
    "#     return(f,h,cenx,ceny)\n",
    "# c_fbin_1,c_hbin_1,c_xcen_bin_1,c_ycen_bin_1 = pickle_reader(dir_pickl_array,0)\n",
    "# c_fbin_2,c_hbin_2,c_xcen_bin_2,c_ycen_bin_2 = pickle_reader(dir_pickl_array,1)\n",
    "# c_fbin_3,c_hbin_3,c_xcen_bin_3,c_ycen_bin_3 = pickle_reader(dir_pickl_array,2)\n",
    "# c_fbin_4,c_hbin_4,c_xcen_bin_4,c_ycen_bin_4 = pickle_reader(dir_pickl_array,3)\n",
    "# c_fbin_5,c_hbin_5,c_xcen_bin_5,c_ycen_bin_5 = pickle_reader(dir_pickl_array,4)\n",
    "# c_fbin_6,c_hbin_6,c_xcen_bin_6,c_ycen_bin_6 = pickle_reader(dir_pickl_array,5)\n",
    "# c_fbin_7,c_hbin_7,c_xcen_bin_7,c_ycen_bin_7 = pickle_reader(dir_pickl_array,6)\n",
    "\n",
    "\n",
    "\n",
    "# # create new empty array of the full light curve.\n",
    "# def full_arr_func(arr_list,empty_array):\n",
    "#     leng = int(len(arr_list))\n",
    "#     for i in range(int(len(arr_list))):\n",
    "#         for n in range(len(arr_list[i])):\n",
    "#             empty_array.append(arr_list[i][n])\n",
    "#     return(empty_array)\n",
    "\n",
    "# ch1_ap_ph_list = []\n",
    "# ch2_ap_ph_list =[]\n",
    "# ch1_full_light_curve = []\n",
    "# ch2_full_light_curve = []\n",
    "# ch1_ap_ph_list.append(ap_ph_6_2)\n",
    "# ch1_ap_ph_list.append(ap_ph_3)\n",
    "# ch2_ap_ph_list.append(ap_ph_5)\n",
    "# ch1_ap_ph_list.append(c_fbin_1)\n",
    "# ch2_ap_ph_list.append(ap_ph_4)\n",
    "# ch1_ap_ph_list.append(ap_ph_7)\n",
    "# ch2_ap_ph_list.append(ap_ph_2)\n",
    "# ch1_ap_ph_list.append(ap_ph_6_1)\n",
    "# full_arr_func(ch1_ap_ph_list,ch1_full_light_curve)\n",
    "# full_arr_func(ch2_ap_ph_list,ch2_full_light_curve)\n",
    "# # ----------------------------------------------\n",
    "# ch1_bmjd_list =[];ch2_bmjd_list =[]\n",
    "# ch1_full_bmjd = [];ch2_full_bmjd = []\n",
    "# ch1_bmjd_list.append(bmjd_6_2)\n",
    "# ch1_bmjd_list.append(bmjd_3)\n",
    "# ch2_bmjd_list.append(bmjd_5)\n",
    "# ch1_bmjd_list.append(c_hbin_1)\n",
    "# ch2_bmjd_list.append(bmjd_4)\n",
    "# ch1_bmjd_list.append(bmjd_7)\n",
    "# ch2_bmjd_list.append(bmjd_2)\n",
    "# ch1_bmjd_list.append(bmjd_6_1)\n",
    "# full_arr_func(ch1_bmjd_list,ch1_full_bmjd)\n",
    "# full_arr_func(ch2_bmjd_list,ch2_full_bmjd)\n",
    "# # ----------------------------------------------\n",
    "# ch1_xcen_list =[];ch2_xcen_list =[]\n",
    "# ch1_full_xcen= [];ch2_full_xcen= []\n",
    "# ch1_xcen_list.append(x_cen6_2)\n",
    "# ch1_xcen_list.append(x_cen3)\n",
    "# ch2_xcen_list.append(x_cen5)\n",
    "# ch1_xcen_list.append(c_xcen_bin_1)\n",
    "# ch2_xcen_list.append(x_cen4)\n",
    "# ch1_xcen_list.append(x_cen7)\n",
    "# ch2_xcen_list.append(x_cen2)\n",
    "# ch1_xcen_list.append(x_cen6_1)\n",
    "# full_arr_func(ch1_xcen_list,ch1_full_xcen)\n",
    "# full_arr_func(ch2_xcen_list,ch2_full_xcen)\n",
    "# # ----------------------------------------------\n",
    "# ch1_ycen_list =[];ch2_ycen_list =[]\n",
    "# ch1_full_ycen= [];ch2_full_ycen= []\n",
    "# ch1_ycen_list.append(y_cen6_2)\n",
    "# ch1_ycen_list.append(y_cen3)\n",
    "# ch2_ycen_list.append(y_cen5)\n",
    "# ch1_ycen_list.append(y_cen1)\n",
    "# ch2_ycen_list.append(y_cen4)\n",
    "# ch1_ycen_list.append(y_cen7)\n",
    "# ch2_ycen_list.append(y_cen2)\n",
    "# ch1_ycen_list.append(y_cen6_1)\n",
    "# full_arr_func(ch1_ycen_list,ch1_full_ycen)\n",
    "# full_arr_func(ch2_ycen_list,ch2_full_ycen)\n",
    "# # ----------------------------------------------\n",
    "# ----------------------------------------------\n",
    "# # plt.figure(figsize=(15,10))\n",
    "# plt.plot(ch1_full_bmjd,ch1_full_light_curve,'.')\n",
    "# plt.plot(ch2_full_bmjd,ch2_full_light_curve,'.')\n",
    "\n",
    "# ## Creating a ASCII file for the WHOLE light curve that's split between two channels.\n",
    "# ch1_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/'+'ch1_full_LightCurve'+'.txt'\n",
    "# Tot_arr_table = Table([ch1_full_light_curve,ch1_full_bmjd,ch1_full_xcen,ch1_full_ycen], names=['AperturePhot','bmjd','x_com_cen','y_com_cen'])\n",
    "# # ascii.write(Tot_arr_table, ch1_dir, format='tab', fast_writer=False) \n",
    "\n",
    "# ch2_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/'+'ch2_full_LightCurve'+'.txt'\n",
    "# Tot_arr_table = Table([ch2_full_light_curve,ch2_full_bmjd,ch2_full_xcen,ch2_full_ycen], names=['AperturePhot','bmjd','x_com_cen','y_com_cen'])\n",
    "# # ascii.write(Tot_arr_table, ch2_dir, format='tab', fast_writer=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def choose_ipsv(maxorder):\n",
    "#     def ipsv_model(xy_arr,*p):\n",
    "#         x=xy_arr[0,:]\n",
    "#         y=xy_arr[1,:]\n",
    "#         x_bar=np.mean(xy_arr[0,:])\n",
    "#         y_bar=np.mean(xy_arr[1,:])\n",
    "        \n",
    "#         index_ipsv = 1\n",
    "#         ipsv = p[0]\n",
    "#         for i in range(maxorder):\n",
    "#             order=i+1\n",
    "#             loop_order=i+2\n",
    "#             for j in range(loop_order):\n",
    "#                 ipsv=ipsv+p[index_ipsv]*(x-x_bar)**(order-j)*(y-y_bar)**(j)\n",
    "#                 index_ipsv=index_ipsv+1\n",
    "# #         print(index_ipsv)\n",
    "#         return(ipsv)\n",
    "#     return(ipsv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ch1_ap_ph_list.append(ap_ph_6_2)\n",
    "# ch1_ap_ph_list.append(c_fbin_3)\n",
    "# ch2_ap_ph_list.append(c_fbin_5)\n",
    "# ch1_ap_ph_list.append(c_fbin_1)\n",
    "# ch2_ap_ph_list.append(c_fbin_4)\n",
    "# ch1_ap_ph_list.append(c_fbin_7)\n",
    "# ch2_ap_ph_list.append(c_fbin_2)\n",
    "# ch1_ap_ph_list.append(c_fbin_6)\n",
    "# full_arr_func(ch1_ap_ph_list,ch1_full_light_curve)\n",
    "# full_arr_func(ch2_ap_ph_list,ch2_full_light_curve)\n",
    "# # ----------------------------------------------\n",
    "# ch1_bmjd_list =[];ch2_bmjd_list =[]\n",
    "# ch1_full_bmjd = [];ch2_full_bmjd = []\n",
    "# # ch1_bmjd_list.append(bmjd_6_2)\n",
    "# ch1_bmjd_list.append(c_hbin_3)\n",
    "# ch2_bmjd_list.append(c_hbin_5)\n",
    "# ch1_bmjd_list.append(c_hbin_1)\n",
    "# ch2_bmjd_list.append(c_hbin_4)\n",
    "# ch1_bmjd_list.append(c_hbin_7)\n",
    "# ch2_bmjd_list.append(c_hbin_2)\n",
    "# ch1_bmjd_list.append(c_hbin_6)\n",
    "# full_arr_func(ch1_bmjd_list,ch1_full_bmjd)\n",
    "# full_arr_func(ch2_bmjd_list,ch2_full_bmjd)\n",
    "# # ----------------------------------------------\n",
    "# ch1_xcen_list =[];ch2_xcen_list =[]\n",
    "# ch1_full_xcen= [];ch2_full_xcen= []\n",
    "# # ch1_xcen_list.append(x_cen6_2)\n",
    "# ch1_xcen_list.append(c_xcen_bin_3)\n",
    "# ch2_xcen_list.append(c_xcen_bin_5)\n",
    "# ch1_xcen_list.append(c_xcen_bin_1)\n",
    "# ch2_xcen_list.append(c_xcen_bin_4)\n",
    "# ch1_xcen_list.append(c_xcen_bin_7)\n",
    "# ch2_xcen_list.append(c_xcen_bin_2)\n",
    "# ch1_xcen_list.append(c_xcen_bin_6)\n",
    "# full_arr_func(ch1_xcen_list,ch1_full_xcen)\n",
    "# full_arr_func(ch2_xcen_list,ch2_full_xcen)\n",
    "# # ----------------------------------------------\n",
    "# ch1_ycen_list =[];ch2_ycen_list =[]\n",
    "# ch1_full_ycen= [];ch2_full_ycen= []\n",
    "# # ch1_ycen_list.append(y_cen6_2)\n",
    "# ch1_ycen_list.append(c_ycen_bin_3)\n",
    "# ch2_ycen_list.append(c_ycen_bin_5)\n",
    "# ch1_ycen_list.append(c_ycen_bin_1)\n",
    "# ch2_ycen_list.append(c_ycen_bin_4)\n",
    "# ch1_ycen_list.append(c_ycen_bin_7)\n",
    "# ch2_ycen_list.append(c_ycen_bin_2)\n",
    "# ch1_ycen_list.append(c_ycen_bin_6)\n",
    "# full_arr_func(ch1_ycen_list,ch1_full_ycen)\n",
    "# full_arr_func(ch2_ycen_list,ch2_full_ycen)\n",
    "# # ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nov22 2019\n",
    "# prot = 5.0\n",
    "# j=.11\n",
    "\n",
    "# x_time=ch1_full_bmjd\n",
    "# y_lc=ch1_med_full_light_curve\n",
    "# x_time=ch1_full_bmjd\n",
    "# y_lc=ch1_med_full_light_curve\n",
    "# plt.figure(figsize=(9,5))\n",
    "\n",
    "# for i in range(1):\n",
    "#     protadj = prot+j\n",
    "#     hr=(x_time-x_time[0])*24 % protadj\n",
    "#     plt.plot(hr,y_lc,'.')\n",
    "#     j=j+0.05\n",
    "# #     plt.show() \n",
    "\n",
    "# def protadj(prot,adj,n_loops,x,y,ch1_oriTime):    \n",
    "#     prot = prot\n",
    "#     j=adj\n",
    "#     x=x\n",
    "#     y=y\n",
    "#     plt.figure(figsize=(9,5))\n",
    "#     for i in range(n_loops):\n",
    "#         protadj = prot+j\n",
    "#         hr=(x-ch1_oriTime[0])*24 % protadj\n",
    "#         plt.plot(hr,y,'.')\n",
    "#         j=j+j\n",
    "        \n",
    "# protadj(5.00,1.8,2,ch1_full_bmjd,ch1_med_full_light_curve,ch1_full_bmjd)\n",
    "                \n",
    "# protadj(5.00,.3,1,ch2_full_bmjd,ch2_med_full_light_curve,ch1_full_bmjd)\n",
    "        \n",
    "# #     plt.show() \n",
    "\n",
    "\n",
    "# WILL NEED AGAIN\n",
    "# ch1_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/'+'ch1_full_MedianLC'+'.txt'\n",
    "# Tot_arr_table = Table([ch1_med_full_light_curve,ch1_full_bmjd,ch1_full_xcen,ch1_full_ycen], names=['AperturePhot','bmjd','x_com_cen','y_com_cen'])\n",
    "# ascii.write(Tot_arr_table, ch1_dir, format='tab', fast_writer=False) \n",
    "\n",
    "# ch2_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/'+'ch2_full_MedianLC'+'.txt'\n",
    "# Tot_arr_table = Table([ch2_med_full_light_curve,ch2_full_bmjd,ch2_full_xcen,ch2_full_ycen], names=['AperturePhot','bmjd','x_com_cen','y_com_cen'])\n",
    "# ascii.write(Tot_arr_table, ch2_dir, format='tab', fast_writer=False) \n",
    "\n",
    "# ch_dir='/Users/melaniapena/Rsrch/Luhman_16_Research/ap_phot_ascii_com/'+'bothCH_full_MedianLC'+'.txt'\n",
    "# Tot_arr_table = Table([med_full_light_curve,full_bmjd,full_xcen,full_ycen], names=['AperturePhot','bmjd','x_com_cen','y_com_cen'])\n",
    "# ascii.write(Tot_arr_table, ch_dir, format='tab', fast_writer=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nov 29 from Luhman_Lightcurve_View\n",
    "# ang_freqs = (2 * np.pi / periods)\n",
    "# pgram = signal.lombscargle(test_t, test_x,ang_freqs,normalize=True)\n",
    "# plt.plot(f, pgram)\n",
    "# plt.plot(test_t,test_x)\n",
    "# plt.xlim(0,20)\n",
    "\n",
    "\n",
    "# # xvaluefinder(frequency,powera,6,100,'yes')\n",
    "# # a=20;b=a+30\n",
    "# # samp1 =powers;camp1 =test_t\n",
    "# # samp2 =powers[a:b];camp2 =test_t[a:b]\n",
    "# # print(len(samp1),len(samp2))\n",
    "# # plt.xlim(0,20)\n",
    "# # plt.plot(camp1,samp1)\n",
    "# # plt.plot(camp2,samp2)\n",
    "\n",
    "# # pwr=samp2\n",
    "# # t= camp\n",
    "# # maxpower=np.amax(pwr);\n",
    "# # print(maxpower,'\\n')\n",
    "\n",
    "# # for i in range(len(pwr)):\n",
    "# # # #     print(pwr[i])\n",
    "# #     if maxpower == pwr[i]:\n",
    "# #         print('Max Pwr:',maxpower)\n",
    "# #         print('index:',i)\n",
    "# #         print('period at index:',t[i])\n",
    "# def xvaluefinder(t,y,i_a,i_b,isit_freq):\n",
    "# #     NOTE\n",
    "# #     You would need to know whether 1) your period 't' is in\n",
    "# #     frequency or not. 2) you would also need to know what your \n",
    "# #     a and b index values are... The a and b can be two values from\n",
    "# #     the x axis so you can set it between the hump of the graph\n",
    "# #     to find the maximum value from the y axis. It is recomended \n",
    "# #     to give two points where the graph has only one hump. it is fine\n",
    "# #     if there are multiple as long there is one maximum point in the y \n",
    "# #     axis that is largest\n",
    "#     full_t=t;full_y=y;\n",
    "#     sliced_t=t[i_a:i_b];sliced_y=y[i_a:i_b];\n",
    "#     if isit_freq=='yes':\n",
    "#         full_t=1/full_t\n",
    "#     elif isit_freq == 'no':\n",
    "#         full_t=full_t\n",
    "# #     find max power value of sliced value\n",
    "#     maxvalue=np.amax(sliced_y)\n",
    "# #     find the index that's correlated to the max power from data\n",
    "# #     using the full data of t and y.\n",
    "#     for i in range(len(full_y)):\n",
    "#     # #     print(pwr[i])\n",
    "#         if maxvalue == full_y[i]:\n",
    "#             print('Max Pwr:',maxvalue)\n",
    "#             print('index:',i)\n",
    "#             print('period at index:',full_t[i])\n",
    "\n",
    "# # to find a and b below from astropy lombscargle.\n",
    "# # pa =1/frequency\n",
    "# # a=6\n",
    "# # b=100\n",
    "# # print(len(powera),len(pa))\n",
    "# # print(len(powera[a:b]),len(pa[a:b]))\n",
    "# # sl_pwra = powera[a:b]\n",
    "# # sl_pa =pa[a:b]\n",
    "# # plt.plot(pa,powera)\n",
    "# # plt.plot(sl_pa,sl_pwra)\n",
    "# # plt.xlim(0,25)\n",
    "# # xvaluefinder(test_t,powers,20,50,'no')\n",
    "# xvaluefinder(frequency,powera,6,100,'yes')\n",
    "\n",
    "# xvaluefinder(frequency,powerg,6,100,'no')\n",
    "\n",
    "# val1 = test_t[0]\n",
    "\n",
    "# maxpower=np.amax(powers);\n",
    "# # print(maxpower)\n",
    "# for i in range(len(powers)):\n",
    "# #     print(powers[i])\n",
    "#     if maxpower == powers[i]:\n",
    "#         print(maxpower)\n",
    "#         print(i)\n",
    "#         print(test_t[i])\n",
    "\n",
    "# pwr=powera\n",
    "# t= 1/frequency\n",
    "# maxpower=np.amax(pwr);\n",
    "# print(maxpower,'\\n')\n",
    "# for i in range(len(pwr)):\n",
    "# #     print(pwr[i])\n",
    "#     if maxpower == pwr[i]:\n",
    "#         print('Max Pwr:',maxpower)\n",
    "#         print('index:',i)\n",
    "#         print('period at index:',t[i])\n",
    "# ----\n",
    "# a=20;b=a+30\n",
    "# samp1 =powers;camp1 =test_t\n",
    "# samp2 =powers[a:b];camp2 =test_t[a:b]\n",
    "# print(len(samp1),len(samp2))\n",
    "# plt.xlim(0,20)\n",
    "# plt.plot(camp1,samp1)\n",
    "# plt.plot(camp2,samp2)\n",
    "\n",
    "# pwr=samp2\n",
    "# t= camp\n",
    "# maxpower=np.amax(pwr);\n",
    "# print(maxpower,'\\n')\n",
    "\n",
    "# for i in range(len(pwr)):\n",
    "# # #     print(pwr[i])\n",
    "#     if maxpower == pwr[i]:\n",
    "#         print('Max Pwr:',maxpower)\n",
    "#         print('index:',i)\n",
    "#         print('period at index:',t[i])\n",
    "\n",
    "# to find a and b below\n",
    "# ---frequency, powera\n",
    "# pa =1/frequency\n",
    "# a=6\n",
    "# b=100\n",
    "# print(len(powera),len(pa))\n",
    "# print(len(powera[a:b]),len(pa[a:b]))\n",
    "# sl_pwra = powera[a:b]\n",
    "# sl_pa =pa[a:b]\n",
    "# plt.plot(pa,powera)\n",
    "# plt.plot(sl_pa,sl_pwra)\n",
    "# plt.xlim(0,25);plt.show()\n",
    "\n",
    "# ---period, powerg\n",
    "# pg =period\n",
    "# a=6\n",
    "# b=100\n",
    "# print(len(powerg),len(pa))\n",
    "# print(len(powerg[a:b]),len(pg[a:b]))\n",
    "# sl_pwrg = powerg[a:b]\n",
    "# sl_pg =pg[a:b]\n",
    "# plt.plot(pg,powerg)\n",
    "# plt.plot(sl_pg,sl_pwrg)\n",
    "# plt.xlim(0,25)\n",
    "\n",
    "# -----\n",
    "\n",
    "# from gatspy.periodic import LombScargle\n",
    "# periods = np.linspace(.05,14, 1000)\n",
    "# ang_freqs = (2 * np.pi / periods)\n",
    "# model = LombScargle(fit_offset=True).fit(t, y)\n",
    "# power = model.score(periods)\n",
    "# plt.plot(periods, power)\n",
    "\n",
    "# ang_freqs = (2 * np.pi / periods)\n",
    "# model1 = LombScargle(fit_offset=True).fit(t1, y1)\n",
    "# power1= model1.score(periods)\n",
    "# plt.plot(periods, power1)\n",
    "\n",
    "# ang_freqs = (2 * np.pi / periods)\n",
    "# model2 = LombScargle(fit_offset=True).fit(t2, y2)\n",
    "# power2 = model2.score(periods)\n",
    "# plt.plot(periods, power2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # model = LombScargleFast().fit(t, test_x)\n",
    "# # period, power = model.periodogram_auto(nyquist_factor=200)\n",
    "# # print(\"period range: ({0}, {1})\".format(period.min(), period.max()))\n",
    "# # print(\"number of periods: {0}\".format(len(period)))\n",
    "# # plt.plot(period,power)\n",
    "# # plt.xlim(0,50)\n",
    "\n",
    "# # frequency, power = LombScargle(t, y).autopower()\n",
    "# # frequency1, power1 = LombScargle(t1, y1).autopower()\n",
    "# # frequency2, power2 = LombScargle(t2, y2).autopower()\n",
    "# # frequency[np.argmax(power)];frequency1[np.argmax(power1)];frequency2[np.argmax(power2)]\n",
    "# # plt.plot(frequency, power) \n",
    "# # plt.plot(frequency1, power1) \n",
    "# # plt.plot(frequency2, power2) \n",
    "\n",
    "# # plt.show()\n",
    "\n",
    "# -----\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.signal as signal\n",
    "\n",
    "# f = (np.linspace(0.05, 1, nout))\n",
    "# ans= True\n",
    "# pgram = signal.lombscargle(t, y, f, normalize=ans)\n",
    "# pgram1 = signal.lombscargle(t1, y1, f, normalize=ans)\n",
    "# pgram2 = signal.lombscargle(t2, y2, f, normalize=ans)\n",
    "# plt.plot(1/f, pgram)\n",
    "# plt.plot(1/f, pgram1)\n",
    "# plt.plot(1/f, pgram2)\n",
    "# # plt.xlim(1,8)\n",
    "\n",
    "# from astropy.timeseries import LombScargle\n",
    "# import astropy\n",
    "# frequency, power = LombScargle(t, y).autopower(minimum_frequency=0.1,maximum_frequency=1.9)\n",
    "# frequency1, power1 = LombScargle(t1, y1).autopower(minimum_frequency=0.1,maximum_frequency=1.9)\n",
    "# frequency2, power2 = LombScargle(t2, y2).autopower(minimum_frequency=0.1,maximum_frequency=1.9)\n",
    "# plt.plot(1/frequency, power) \n",
    "# plt.plot(1/frequency1, power1) \n",
    "# plt.plot(1/frequency2, power2) \n",
    "# plt.show()\n",
    "# plt.plot(1/frequency, power) \n",
    "# plt.plot(1/frequency1, power1) \n",
    "# plt.plot(1/frequency2, power2) \n",
    "# plt.xlim(4.5,6)\n",
    "# print(len(frequency))\n",
    "\n",
    "# -----\n",
    "\n",
    "# import scipy.signal as signal\n",
    "# nout = 10000\n",
    "\n",
    "# f = np.linspace(.07, 14, nout)\n",
    "# T = 1/f\n",
    "# ch1_LombScargle = signal.lombscargle(hr1, ch1_med_full_light_curve, f, normalize=True)\n",
    "# ch2_LombScargle = signal.lombscargle(hr2, ch2_med_full_light_curve, f, normalize=True)\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# Full_LombScargle = signal.lombscargle(hours, med_full_light_curve, f, normalize=True)\n",
    "# plt.subplot(2, 1, 2);plt.title('Ch1 and Ch2 Lomb Scargle P.');plt.plot(T, Full_LombScargle)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# # plt.subplot(2, 1, 1);plt.title('Ch1 LightCurve');plt.plot(hr1, ch1_med_full_light_curve, '.')\n",
    "# plt.subplot(2, 1, 1);plt.title('Ch1 Lomb Scargle Periodogram');plt.plot(T, ch1_LombScargle)\n",
    "# plt.xlabel('Period'),plt.ylabel('Intensity');\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(10,8))\n",
    "# # plt.subplot(2, 1, 1);plt.title('Ch2 LightCurve');plt.plot(hr2, ch2_med_full_light_curve, '.')\n",
    "# plt.subplot(2, 1, 2);plt.title('Ch2 Lomb Scargle Periodogram');plt.plot(T, ch2_LombScargle)\n",
    "# plt.xlabel('Period'),plt.ylabel('Intensity');\n",
    "# -----\n",
    "# # checking if values are in correct order for time (bmjd)\n",
    "# print(c_fbin_3[0],c_fbin_3[-1],'CH1--',c_hbin_3[0],c_hbin_3[-1])\n",
    "\n",
    "# print(c_fbin_5[0],c_fbin_5[-1],'CH2--',c_hbin_5[0],c_hbin_5[-1])\n",
    "\n",
    "# print(c_fbin_1[0],c_fbin_1[-1],'CH1--',c_hbin_1[0],c_hbin_1[-1])\n",
    "\n",
    "# print(c_fbin_4[0],c_fbin_4[-1],'CH2--',c_hbin_4[0],c_hbin_4[-1])\n",
    "\n",
    "# print(c_fbin_7[0],c_fbin_7[-1],'CH1--',c_hbin_7[0],c_hbin_7[-1])\n",
    "\n",
    "# print(c_fbin_2[0],c_fbin_2[-1],'CH2--',c_hbin_2[0],c_hbin_2[-1])\n",
    "\n",
    "# print(c_fbin_6[0],c_fbin_6[-1],'CH1--',c_hbin_6[0],c_hbin_6[-1])\n",
    "# print('')\n",
    "# # print(c_fbin_2[0],c_fbin_2[-1])\n",
    "\n",
    "# ------\n",
    "\n",
    "\n",
    "# from astropy.timeseries import LombScargle\n",
    "# import astropy\n",
    "# # astropy.test()\n",
    "# y = med_full_light_curve\n",
    "# t = hours\n",
    "# frequencya, powera = LombScargle(t, y).autopower(minimum_frequency=0.07, maximum_frequency=8)\n",
    "\n",
    "# y = ch1_med_full_light_curve\n",
    "# t = hr1\n",
    "# frequency1, power1 = LombScargle(t, y).autopower(minimum_frequency=0.07, maximum_frequency=8)\n",
    "\n",
    "# y = ch2_med_full_light_curve\n",
    "# t = hr2\n",
    "# frequency2, power2 = LombScargle(t, y).autopower(minimum_frequency=0.07, maximum_frequency=8)\n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.plot(1/frequencya,powera)\n",
    "# plt.plot(1/frequency1,power1)\n",
    "# plt.plot(1/frequency2,power2)\n",
    "\n",
    "# n=3\n",
    "# plt.xlim(n,n+7)\n",
    "# ----\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.signal as signal\n",
    "# def lombscargle_scipy(t,y):\n",
    "#     f = (2*np.pi)/t\n",
    "#     powers = signal.lombscargle(t, y, f, normalize=True)\n",
    "#     periods = t\n",
    "#     plt.plot(t, powers)\n",
    "#     plt.title('Lomgscargle (Using scipy)')\n",
    "#     plt.xlabel('Period');plt.ylabel('Power')\n",
    "#     return(periods,powers)\n",
    "\n",
    "# periods, powers = lombscargle_scipy(t,y)\n",
    "# periods1, powers1 = lombscargle_scipy(t1,y1)\n",
    "# periods2, powers2 = lombscargle_scipy(t2,y2)\n",
    "# # plt.xlim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# from astropy.timeseries import LombScargle\n",
    "# import astropy\n",
    "# def lombscargle_astropy(t,y,lab_str):\n",
    "#     frequency, powera = LombScargle(t, y).autopower()\n",
    "#     perioda = 1/frequency\n",
    "#     plt.plot(perioda,powera,label=lab_str)\n",
    "#     plt.title('Lomgscargle (Using astropy)')\n",
    "#     plt.xlabel('Period');plt.ylabel('Power')\n",
    "#     return(perioda,powera)\n",
    "\n",
    "# # plt.figure(figsize=(12,8))\n",
    "# # plt.title('Lomgscargle (Using astropy)')\n",
    "# # perioda, powera = lombscargle_astropy(t,y,'Full')\n",
    "# # perioda1, powera1 = lombscargle_astropy(t1,y1,'Ch1')\n",
    "# # perioda2, powera2 = lombscargle_astropy(t2,y2,'Ch2')\n",
    "# # plt.legend(loc='upper right',frameon=1,fontsize=16);\n",
    "# # plt.xlim(0,63);\n",
    "# # plt.show()\n",
    "# # plt.figure(figsize=(12,8))\n",
    "# # perioda, powera = lombscargle_astropy(t,y,'Full')\n",
    "# # perioda1, powera1 = lombscargle_astropy(t1,y1,'Ch1')\n",
    "# # perioda2, powera2 = lombscargle_astropy(t2,y2,'Ch2')\n",
    "# # plt.title('Lomgscargle (Using astropy, zoomed in between hrs 4 and 7)')\n",
    "# # plt.legend(loc='upper right',frameon=1,fontsize=16);\n",
    "# # plt.xlim(4.2,7);plt.ylim(0,.16)\n",
    "\n",
    "# # plt.axvline(x=4.8,ymin=.441, ymax=.058, color='r', linestyle='--')\n",
    "# # plt.axvline(x=4.8+1.0,ymin=.441, ymax=.058, color='r', linestyle='--')\n",
    "# # plt.axhline(y=.07,xmin=.212, xmax=.572, color='r', linestyle='--')\n",
    "# # plt.axhline(y=.07-.06,xmin=.212, xmax=.572, color='r', linestyle='--')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def xvaluefinder(t,y,i_a,i_b,isit_freq):\n",
    "# #     NOTE\n",
    "# #     You would need to know whether 1) your period 't' is in\n",
    "# #     frequency or not. 2) you would also need to know what your \n",
    "# #     a and b index values are... The a and b can be two values from\n",
    "# #     the x axis so you can set it between the hump of the graph\n",
    "# #     to find the maximum value from the y axis. It is recomended \n",
    "# #     to give two points where the graph has only one hump. it is fine\n",
    "# #     if there are multiple as long there is one maximum point in the y \n",
    "# #     axis that is largest\n",
    "#     full_t=t;full_y=y;\n",
    "#     sliced_t=t[i_a:i_b];sliced_y=y[i_a:i_b];\n",
    "#     if isit_freq=='yes':\n",
    "#         full_t=1/full_t\n",
    "#     elif isit_freq == 'no':\n",
    "#         full_t=full_t\n",
    "# #     find max power value of sliced value\n",
    "#     maxvalue=np.amax(sliced_y)\n",
    "# #     find the index that's correlated to the max power from data\n",
    "# #     using the full data of t and y.\n",
    "#     for i in range(len(full_y)):\n",
    "#     # #     print(pwr[i])\n",
    "#         if maxvalue == full_y[i]:\n",
    "#             print('Max Pwr:',maxvalue)\n",
    "# #             print('index:',i)\n",
    "#             print('period at index:',full_t[i],'\\n')\n",
    "#             result=full_t[i]\n",
    "#     return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg =periodg1\n",
    "# pwr = powerg1\n",
    "\n",
    "# a=55\n",
    "# b=64\n",
    "\n",
    "# print(len(pwr),len(pg))\n",
    "# print(len(pwr[a:b]),len(pg[a:b]))\n",
    "# sl_pwr = pwr[a:b]\n",
    "# sl_pg =pg[a:b]\n",
    "# plt.plot(pg,pwr)\n",
    "# plt.plot(sl_pg,sl_pwr)\n",
    "# plt.xlim(4.6,5.7);\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protg=xvaluefinder(periodg,powerg,55,64,'no')\n",
    "# protg1=xvaluefinder(periodg1,powerg1,55,64,'no')##\n",
    "# protg2=xvaluefinder(periodg2,powerg2,45,52,'no')##\n",
    "\n",
    "# from gatspy import datasets, periodic\n",
    "# model = periodic.LombScargleFast(fit_period=True)\n",
    "# model.optimizer.set(period_range=(.5, 5.7), first_pass_coverage=5)\n",
    "# model.fit(t2, y2)\n",
    "# val =model.best_period\n",
    "# print(val)\n",
    "# print(val)\n",
    "# periodg, powerg = lombscargle_gatspy(t,y,'Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# luhman plot view jan 22 2020\n",
    "# x=56870 (?)\n",
    "# plt.xlim(x+.6,x+.8)\n",
    "# plt.xlim(x+1.09,x+1.1)\n",
    "# plt.xlim(x+1.5,x+1.6)\n",
    "# plt.xlim(x+1.9,x+2)\n",
    "# plt.xlim(x+2.35,x+2.4)\n",
    "# plt.xlim(x+2.7,x+2.85)\n",
    "\n",
    "# plt.ylim(267000,490000)\n",
    "# plt.ylim(.95,1.040)\n",
    "# plt.ylim(290000,310000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 24 2020\n",
    "# luhman plot view\n",
    "\n",
    "\n",
    "# def choose_fourier(nmode):##editted one\n",
    "#     def fourier_model(x,*fp):\n",
    "#         fourier = fp[1] ##setting the offset first.\n",
    "#         print(fourier)\n",
    "#         for i in range(nmode+1):\n",
    "#             n=i\n",
    "#             fourier = fourier + fp[2+i*2]*np.cos(2.*np.pi*n*x/fp[0]) + fp[3+i*2]*np.sin(2.*np.pi*n*x/fp[0])\n",
    "#         return(fourier)\n",
    "#     return(fourier_model)\n",
    "\n",
    "#                 ipsv=ipsv+p[index_ipsv]*(x-x_bar)**(order-j)*(y-y_bar)**(j)\n",
    "#                 index_ipsv=index_ipsv+1\n",
    "# #         print(index_ipsv)\n",
    "#         return(ipsv)\n",
    "#     return(ipsv_model)\n",
    "\n",
    "# print(len(ap_ph_1)+len(ap_ph_2)+len(ap_ph_3)+len(ap_ph_4)+len(ap_ph_5)+len(ap_ph_6_1)+len(ap_ph_7))\n",
    "# x=4.6\n",
    "# plt.ylim(.95,1.040)\n",
    "# plt.ylim(290000,310000)\n",
    "# ----------------------------\n",
    "# # create new empty array of the full light curve.\n",
    "# def full_arr_func(arr_list,empty_array):\n",
    "#     leng = int(len(arr_list))\n",
    "#     for i in range(int(len(arr_list))):\n",
    "#         for n in range(len(arr_list[i])):\n",
    "#             empty_array.append(arr_list[i][n])\n",
    "#     return(empty_array)\n",
    "# def creatingFull_LC_AsOneArray(ap_ph_list,full_LC,binArr):\n",
    "#     length_arr = len(binArr)\n",
    "#     for i in range(length_arr):\n",
    "#         ap_ph_list.append(binArr[i])\n",
    "#     full_arr_func(ap_ph_list,full_LC)\n",
    "#     return(full_LC)\n",
    "# # Creating arrays of the flux,time, x centroids and y centroid placed in \n",
    "# #  either channel number for each Lightcurve segment. I placed the segments in order\n",
    "# #  depending on it's given time of 'bmjd'. So when we append a part from a segment \n",
    "# #  it falls align with the bmjd arr. This applies for both Channel 1 and Channel 2.\n",
    "\n",
    "# # Clipped flux array that's binned for every certain amount of data points.\n",
    "# ch1_f_arr= [ap_ph_3,ap_ph_1,ap_ph_7,ap_ph_6_1]\n",
    "# ch2_f_arr= [ap_ph_5,ap_ph_4,ap_ph_2]\n",
    "# # Clipped time measured in 'bmjd' that's binned for every certain amount of data points.\n",
    "# ch1_h_arr= [bmjd_3,bmjd_1,bmjd_7,bmjd_6_1]\n",
    "# ch2_h_arr= [bmjd_5,bmjd_4,bmjd_2]\n",
    "# # Clipped x centroid measured that's binned for every certain amount of data points.\n",
    "# ch1_xcen_arr= [x_cen3,x_cen1,x_cen7,x_cen6_1]\n",
    "# ch2_xcen_arr= [x_cen5,x_cen4,x_cen2]\n",
    "# # Clipped y centroid measured that's binned for every certain amount of data points.\n",
    "# ch1_ycen_arr= [y_cen3,y_cen1,y_cen7,y_cen6_1]\n",
    "# ch2_ycen_arr= [y_cen5,y_cen4,y_cen2]\n",
    "# # -------\n",
    "# # Here we create a list where the list_arr saves a value that's placed from 1 to 8 segments \n",
    "# #  Not only that, we append each value placement into the full_array. \n",
    "# #  'creatingFull_LC_AsOneArray' uses another definition within itself titled 'full_arr_func'\n",
    "\n",
    "# # Lightcurve\n",
    "# ch1_r_ap_ph_list = [];ch1_rfull_light_curve = []\n",
    "# ch2_r_ap_ph_list =[];ch2_rfull_light_curve = []\n",
    "# creatingFull_LC_AsOneArray(ch1_r_ap_ph_list,ch1_rfull_light_curve,ch1_f_arr)\n",
    "# creatingFull_LC_AsOneArray(ch2_r_ap_ph_list,ch2_rfull_light_curve,ch2_f_arr)\n",
    "# # time\n",
    "# ch1_hr_list =[];ch1_full_hr = []\n",
    "# ch2_hr_list =[];ch2_full_hr = []\n",
    "# creatingFull_LC_AsOneArray(ch1_hr_list,ch1_full_hr,ch1_h_arr)\n",
    "# creatingFull_LC_AsOneArray(ch2_hr_list,ch2_full_hr,ch2_h_arr)\n",
    "# # XCEN\n",
    "# ch1_xcen_list =[];ch1_full_xcen= []\n",
    "# ch2_xcen_list =[];ch2_full_xcen= []\n",
    "# creatingFull_LC_AsOneArray(ch1_xcen_list,ch1_full_xcen,ch1_xcen_arr)\n",
    "# creatingFull_LC_AsOneArray(ch2_xcen_list,ch2_full_xcen,ch2_xcen_arr)\n",
    "# # YCEN\n",
    "# ch1_ycen_list =[];ch1_full_ycen= []\n",
    "# ch2_ycen_list =[];ch2_full_ycen= []\n",
    "# creatingFull_LC_AsOneArray(ch1_ycen_list,ch1_full_ycen,ch1_ycen_arr)\n",
    "# creatingFull_LC_AsOneArray(ch2_ycen_list,ch2_full_ycen,ch2_ycen_arr)\n",
    "\n",
    "# plt.plot(ch1_full_hr,ch1_rfull_light_curve,'.')\n",
    "# plt.plot(ch2_full_hr,ch2_rfull_light_curve,'.')\n",
    "# print('complete')\n",
    "# ------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ExtArrMedFunct(x3,x5,x1,x4,x7,x2,x6_1):\n",
    "#     final_arr=[]\n",
    "#     ch1_arr=[]\n",
    "#     ch2_arr=[]\n",
    "#     final_arr.extend(x3);ch1_arr.extend(x3)\n",
    "#     final_arr.extend(x5);ch2_arr.extend(x5)\n",
    "#     final_arr.extend(x1);ch1_arr.extend(x1)\n",
    "#     final_arr.extend(x4);ch2_arr.extend(x4)\n",
    "#     final_arr.extend(x7);ch1_arr.extend(x7)\n",
    "#     final_arr.extend(x2);ch2_arr.extend(x2)\n",
    "#     final_arr.extend(x6_1);ch1_arr.extend(x6_1)\n",
    "#     Tot_arr_table = Column(final_arr, name='Column')#change its type from list to astropy column to mask data points\n",
    "#     ch1_arr_table = Column(ch1_arr, name='Column')\n",
    "#     ch2_arr_table = Column(ch2_arr, name='Column')\n",
    "    \n",
    "#     x3=median_flux(x3,ch1_arr_table)\n",
    "#     x5=median_flux(x5,ch2_arr_table)\n",
    "#     x1=median_flux(x1,ch1_arr_table)\n",
    "#     x4=median_flux(x4,ch2_arr_table)\n",
    "#     x7=median_flux(x7,ch1_arr_table)\n",
    "#     x2=median_flux(x2,ch2_arr_table)\n",
    "#     x6_1=median_flux(x6_1,ch1_arr_table)\n",
    "    \n",
    "#     final_arr=[];ch1_arr=[];ch2_arr=[]\n",
    "#     final_arr.extend(x3);ch1_arr.extend(x3)\n",
    "#     final_arr.extend(x5);ch2_arr.extend(x5)\n",
    "#     final_arr.extend(x1);ch1_arr.extend(x1)\n",
    "#     final_arr.extend(x4);ch2_arr.extend(x4)\n",
    "#     final_arr.extend(x7);ch1_arr.extend(x7)\n",
    "#     final_arr.extend(x2);ch2_arr.extend(x2)\n",
    "#     final_arr.extend(x6_1);ch1_arr.extend(x6_1)\n",
    "#     Tot_arr_table = Column(final_arr, name='Column')#change its type from list to astropy column to mask data points\n",
    "#     ch1_arr_table = Column(ch1_arr, name='Column')\n",
    "#     ch2_arr_table = Column(ch2_arr, name='Column')\n",
    "#     return Tot_arr_table,ch1_arr_table,ch2_arr_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # n=.970;m=1.04\n",
    "# n=440000;m=465000;\n",
    "# plt.ylim(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mar12020\n",
    "# def choose_fourier(nmode,seg_identifier):\n",
    "#     def fourier_model(x,*fp):\n",
    "#         fourier = fp[1] ##setting the offset first.\n",
    "# #         print(fourier)\n",
    "#         for i in range(nmode):\n",
    "#             n=i+1\n",
    "#             fourier = fourier + fp[2+i*2]*np.cos(2.*np.pi*n*x/fp[0]) + fp[3+i*2]*np.sin(2.*np.pi*n*x/fp[0])\n",
    "#         return(fourier)\n",
    "#     return(fourier_model)\n",
    "\n",
    "# def median_flux(ap_ph):\n",
    "#     ap_ph_med = ap_ph/np.nanmedian(ap_ph)\n",
    "#     return ap_ph_med\n",
    "\n",
    "# def choose_fourier_jr(nmode, npoly):\n",
    "#     def fourier_model(x,*fp):\n",
    "#         a0_coeffs = fp[0:npoly+1]\n",
    "#         fourier = np.polyval(a0_coeffs, x) ##setting the offset first.\n",
    "#         print(fourier)\n",
    "#         for k in range(nmode):\n",
    "#             n=k+1\n",
    "# #             an_coeffs = [npoly+1+(npoly+1)*2*k:npoly+(npoly+1)+1+(npoly+1)*2*k] #Original\n",
    "# #             bn_coeffs = [npoly+1+(npoly+1)+n*2*(poly+1)*2**k:npoly+npoly+1)*2+1+npoly+1)*2*k] #Original\n",
    "            \n",
    "#             an_coeffs = fp[npoly+1+(npoly+1)*2*k:npoly+(npoly+1)+1+(npoly+1)*2*k]\n",
    "#             bn_coeffs = fp[npoly+1+(npoly+1)+n*2*(poly+1)*2**k:npoly+(npoly+1)*2+1+(npoly+1)*2*k]\n",
    "            \n",
    "#             fourier = fourier + np.polyval(an_coeffs,x)*np.cos(2.*np.pi*n*x/fp[0]) + fp[3+i*2]*np.sin(2.*np.pi*n*x/fp[0])\n",
    "#         return(fourier)\n",
    "#     return(fourier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 7\n",
    "# ### guess parameters for fourier\n",
    "# guess_fourier = np.zeros(n_f)\n",
    "# guess_fourier = np.random.randn(n_f)*0.01\n",
    "# # print(guess_fourier)\n",
    "# number = period\n",
    "# period_guess=number#/24 omitted\n",
    "# offset_guess=1\n",
    "# guess_fourier[0] = period_guess\n",
    "# guess_fourier[1+Npoly] = offset_guess\n",
    "# ----\n",
    "# Npoly=1\n",
    "# n_f = (Npoly+1)*(2*nmodes+1)+1\n",
    "# print('Parameters for Fourier model: ',n_f) ## number of paramters for number of fourier terms\n",
    "\n",
    "# ### guess parameters for fourier\n",
    "# guess_fourier = np.zeros(n_f)\n",
    "# guess_fourier = np.random.randn(n_f)*0.01\n",
    "# # print(guess_fourier)\n",
    "# number = period\n",
    "# period_guess=number#/24 omitted\n",
    "# offset_guess=1\n",
    "# guess_fourier[0] = period_guess\n",
    "# guess_fourier[1+Npoly] = offset_guess\n",
    "\n",
    "# model_f1 = choose_fourier_jr(nmodes,Npoly)(c_h,*guess_fourier);\n",
    "# plt.plot(c_h,model_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chi_sqrd(Model, Data, unc):\n",
    "#     two = 2\n",
    "#     chi_squared = sum(((Data - Model) ** two) / unc ** two)\n",
    "#     return chi_squared\n",
    "# # This gives noise from the data\n",
    "# flux_roll = np.roll(c_f,1)\n",
    "# diff = flux_roll - c_f\n",
    "# f_stdev = np.std(diff) / np.sqrt(2)\n",
    "# print('Std: ',f_stdev) ## noise is for each data point 0.2%\n",
    "# chi_2 = chi_sqrd(model_final,c_f,f_stdev)\n",
    "# len_c_f = len(c_f)\n",
    "# chi_val = round(chi_2,3)\n",
    "# chi_div_len_fl = chi_2/(len(c_f))\n",
    "# round_chi_div_len_fl = round(chi_div_len_fl,4)\n",
    "\n",
    "# # The BIC formula:\n",
    "# total_param = n_ipsv+n_f\n",
    "# BIC = round(chi_2 + (np.log(len_c_f)*(total_param)),5)\n",
    "\n",
    "# print('Total Parameters:',total_param)\n",
    "# print('Chi_Sqaured:',chi_2)\n",
    "# print('Length of Flux: ',len(c_f))\n",
    "# print('Chi-Sqrd/len(Flux): ',chi_2/(len(c_f)))\n",
    "# print('BIC: ', BIC/(len(c_f)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
